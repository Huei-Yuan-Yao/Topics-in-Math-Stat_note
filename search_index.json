[["prob.html", "Chapter 2 Measure-based Probability theory", " Chapter 2 Measure-based Probability theory In this chapter, we quickly review the concepts in measure-based probability theory. The measure theory help us rigorously and axiomatically describe the randomness. When it comes to talk about a “probability” of an event, first we have to know about the underlying probability space. "],["probability-spaces-and-random-elements.html", "2.1 Probability Spaces and Random Elements", " 2.1 Probability Spaces and Random Elements 2.1.1 Recap: Measure theory We start from some basic concepts in the classical measure theory and use them to describe the probability space. Definition 2.1 ( \\(\\sigma\\)-algebra) Let \\(\\cal F\\) be a collection of subsets of a sample space \\(\\Omega\\). \\(\\cal F\\) is called a \\(\\sigma\\)-algebra or \\(\\sigma\\)-field on \\(\\Omega\\) if The empty set \\(\\phi \\in \\cal F\\). If \\(A \\in \\cal F\\), then \\(A^c \\in \\cal F\\). If \\(A_i \\in \\cal F\\) for \\(i=1,2,\\cdots\\), then \\(\\cup_{i=1}^{\\infty} A_i \\in \\cal F\\). We denote the smallest sigma algebra containing a collection \\(C\\) as \\(\\sigma(C)\\). In particular, we denote \\(\\cal B= \\sigma(C)\\) the \\(\\sigma\\)-field (called Borel field) where \\(C\\) denotes all finite open interval on \\(\\mathbb{R}\\). By Linderberg’s covering lemma, we can see \\(\\cal B\\) is also the smallest \\(\\sigma\\)-field containing the collection of all open sets on \\(\\mathbb{R}\\). Furthermore, we denote \\(\\cal B^k\\) as the Borel field in \\(\\mathbb{R}^k\\). Define the pair \\((\\Omega, \\cal F)\\) a measurable space if \\(\\cal F\\) is a \\(\\sigma\\)-field on \\(\\Omega\\). Definition 2.2 (Measure) A set function \\(\\nu(\\cdot)\\) defined on a \\(\\sigma\\)-field \\(\\cal F\\) is a measure if \\(0 \\leq \\nu(A) \\leq \\infty\\) for any \\(A \\in \\cal F\\). \\(\\nu(\\phi)=0\\) If \\(A_i \\in \\cal F\\), \\(i=1,2,\\cdots\\) and \\(A_i\\)’s are disjoint for any \\(i\\neq j\\), then \\[\\nu(\\cup_i A_i)=\\sum_i \\nu(A_i)\\] The triple \\((\\Omega, \\cal F, \\nu)\\) is called a measure space and it is called a probability space if \\(\\nu(\\Omega)=1\\). Proposition 2.1 Let \\((\\Omega,\\cal F,\\nu)\\) be a measure space. If \\(A \\subset B \\in \\cal F\\), then \\(\\nu(A)\\leq \\nu (B)\\). For any sequence \\(A_1,A_2,\\cdots \\in \\cal F\\), \\[\\nu(\\cup_i A_i)\\leq \\sum_i \\nu(A_i).\\] If \\(A_1 \\subset A_2 \\subset \\cdots \\in \\cal F\\) (or \\(A_1 \\supset A_2 \\supset \\cdots\\) and \\(\\nu(A_k)&lt;\\infty\\) for some \\(k\\in \\mathbb{N}\\)), then \\[\\nu(\\lim_{k \\to \\infty}A_k)=\\lim_{k\\to \\infty}\\nu(A_k).\\] Below we see some uniqueness theorem about the measure, or the result of the well known Dinkin’s \\(\\pi\\)-\\(\\lambda\\) theorem. Definition 2.3 A collection \\(C\\) of some subsets of \\(\\Omega\\) is a \\(\\pi\\)-system if it is closed under intersection. Definition 2.4 Let \\(C\\) be a collection of some subsets of \\(\\Omega\\). A measure \\(\\mu\\) is \\(\\sigma\\)-finite on \\(C\\) if there exist a sequence of sets \\(\\{A_k\\}\\) in \\(C\\) such that \\(\\Omega=\\cup_k A_k\\) and \\(\\mu(A_K)&lt;\\infty\\) for all \\(k\\). Lebesgue measure is an example of \\(\\sigma\\)-finite measure on \\(\\cal B\\). Since probability measure is always finite, so it is \\(\\sigma\\)-finite. Theorem 2.1 (Theorem 10.3 in Billingsley, 1986) Suppose that \\(\\mu_1\\) and \\(\\mu_2\\) are measures on \\(\\sigma(\\cal P)\\), where \\(\\cal P\\) is a \\(\\pi\\)-system. Suppose they are both \\(\\sigma\\)-finite and agree on \\(\\cal P\\), then they also agree on \\(\\sigma(\\cal P)\\). Example 2.1 Here are some examples using the uniqueness theorem: If \\(\\mu\\) is a measure defined on \\(\\cal B\\) and \\(\\mu([a,b])=b-a\\), then by checking that \\(\\cal P:=\\{[a,b]\\,|-\\infty&lt;a&lt;b&lt;\\infty\\}\\) is a \\(\\pi\\)- system and \\(\\cal B=\\sigma(\\cal P)\\) we can show that \\(\\mu\\) agrees with the Lebesgue measure on \\(\\cal B\\). (Billingsley, pp.225-236, 1986) Given measurable spaces \\((\\Omega_i, \\cal F_i,\\nu_i)_{i=1}^k\\) with \\(\\sigma\\)- finite measures, there exists a unique \\(\\sigma\\)- finite measure on product \\(\\sigma\\)- field \\(\\sigma(\\prod_\\limits{i=1}^k \\cal F_i)\\), which is known as product measure, defined by \\[\\nu_1\\times\\cdots\\times\\nu_k\\,(A_1\\times\\cdots\\times A_k):=\\prod_\\limits{i=1}^k \\nu_i(A_i)\\] for all \\(A_i \\in \\cal F_i,\\,i=1,\\cdots,k\\). 2.1.2 Measurable Functions Definition 2.5 (Measurable functions) Let \\(f\\) be a function from \\((\\Omega,\\cal F)\\) to \\((\\Lambda, \\cal G)\\) (both are measurable spaces). Then \\(f\\) is called a measurable function if \\(f^{-1}(\\cal G) \\subset \\cal F\\), where \\(f^{-1}(\\cal G):=\\{f^{-1}(A)\\,|\\, A\\in \\cal G\\}.\\) In the other words, preimage of any set in \\(\\cal G\\) of a measurable fucntion also lies in \\(\\cal F\\). If \\(\\Lambda=\\mathbb{R}\\) and \\(\\cal G=\\cal B\\), \\(f\\) is called a Borel function. Furthermore, a Borel function defined on a probability space is called a random Variable (a random vector with respect to (\\(\\mathbb{R}^k,\\cal B^k\\))). It is worthy noting that we may not require \\(\\cal F\\) to be the \\(\\sigma\\)- field on which \\(f\\) is measurable. In particular, it is easy to prove that \\(f^{-1}(\\cal G)\\) is also a \\(\\sigma\\)- field. This “smaller \\(\\sigma\\)- field is called \\(\\sigma\\)- field induced by \\(f\\) and we denote it by \\(\\sigma(f)\\). We omit the technical proof of the measurability of a function under fundamental operation such as sup, inf, limsup, liminf. Indicator functions, continuous functions, composition of measurable functions are also measurable functions. Readers can refer to the textbook for the proof. Proposition 2.2 (Approximation property) Suppose that f is measurable from \\((\\Omega,\\cal F)\\) to \\((\\bar{\\mathbb{R}}, \\bar{\\cal B})\\), where \\(\\bar{\\mathbb{R}}\\) is the extended real line with respect to \\(\\bar{\\cal B}\\). First assume \\(f \\geq 0\\), then there exists a positive and monotone sequence of simple functions \\(\\{f_n\\}\\) such that \\(f_n \\to f\\). For general measurable function \\(f\\), consider \\(f=f^{+}-f^{-}\\) for general function \\(f\\) and similar result goes. Below we show a lemma which let us connect two measurable function. Lemma 2.1 (Theorem A.42 in Schervish, 1995) Let \\(Y\\) be measurable from \\((\\Omega,\\cal F)\\) to \\((\\Lambda_Y,\\cal G_Y)\\) and \\(Z\\) be measurable from \\((\\Omega,\\cal F)\\) to \\((\\Lambda_Z,\\cal G_Z)\\). Define \\(T=\\{Y(\\omega),\\omega \\in \\Omega\\} \\subset \\Lambda_Y\\). Then \\(Z\\) is measurable from \\((\\Omega,\\sigma(Y))\\) to \\((\\Lambda_Z,\\cal G_Z)\\) if and only if \\(Z=h \\circ Y\\) for some \\(h\\) that is measurable from \\((T,T\\cap \\cal G_Y)\\) to \\((\\Lambda_Z,\\cal G_Z)\\). Remark: Proof of the “if” side is relatively obvious. (WLOG, we can assume \\(\\Lambda_Y\\) is the range of \\(Y\\).) Proof (only if). At first, we show that for \\(\\omega_1,\\ \\omega_2 \\in \\Omega\\), \\(Y(\\omega_1)=Y(\\omega_2)\\) implies \\(Z(\\omega_1)=Z(\\omega_2)\\). Suppose that \\(Y(\\omega_1)=Y(\\omega_1)=a\\). Since \\(Z\\) is measurable with respect to \\(\\sigma(Y)\\), there exist \\(A \\in \\cal G_Y\\) such that \\(Y^{-1}(A) =Z^{-1}(\\{Z(\\omega_1)\\})\\). Clearly \\(\\omega_1,\\ \\omega_2 \\in Z^{-1}(\\{Z(\\omega_1)\\})\\), thus \\(Z(\\omega_1)=Z(\\omega_2)\\). By this first step, the function \\(h\\) with \\(h(Y(\\omega))=Z(\\omega)\\) is well defined with domain being the range of \\(Y\\). Secondly, we prove such \\(h\\) is measurable with respect to \\(T \\,\\cap\\, \\cal G_Y\\). Given \\(B \\in \\cal G_Z\\), let \\(A\\) be an event in \\(\\cal G_Y\\) such that \\(Y^{-1}(A)=Z^{-1}(B)\\) which exists since \\(Z\\) is measurable with respect to \\(\\sigma(Y)\\), then \\(h\\) is measurable if \\(h^{-1}(B)=A\\,\\cap\\,T\\), where \\(T\\) is the range of \\(Y\\). (\\(h^{-1}(B)\\subset A\\,\\cap\\,T\\)). Given \\(a \\in h^{-1}(B)\\), then \\(h(a) \\in B\\) and \\(a=Y(\\omega)\\) for some \\(\\omega\\in \\Omega\\) (\\(a \\in T\\)) by the domain of \\(h\\), and thus \\(Z(\\omega)=h(Y(\\omega)) \\in B\\), \\(\\omega \\in Z^{-1}(B)=Y^{-1}(A)\\) implies \\(a \\in A\\). (\\(A\\,\\cap\\,T\\subset h^{-1}(B)\\)). Given \\(a \\in A \\cap T\\), \\(a=Y(\\omega) \\in A\\) for some \\(\\omega \\in \\Omega\\), then \\(\\omega \\in Y^{-1}(A)=Z^{-1}(B)\\) and by definition of \\(h\\), \\(h(a)=Z(\\omega)\\in B\\), thus \\(a \\in h^{-1}(B)\\). "],["integration-and-differentiation.html", "2.2 Integration and Differentiation", " 2.2 Integration and Differentiation 2.2.1 Lebesgue integral An usual way to define Lebesgue integral is from simple function to non-negative function by approximation property, then to a general function by an easy decomposition. Let us start from simple function. Assume \\(\\phi=\\sum_\\limits{i=1}^k a_iI_{A_i}\\), \\(A_i\\)’s are disjoint. Then its integral with respect to measure \\(\\nu\\) is \\[\\int \\phi d\\nu=\\sum_\\limits{i=1}^k a_i\\nu(A_i).\\] Clearly \\(A_i\\) is required to be measruable which is equivalent to say \\(\\phi\\) is measurable. It can be seen such integration concept comes from “partition the range” while the Riemann integration comes from partition of the domain. This is also shown in the construction of the approximation property. In particular, we define \\(a\\infty=0\\) when \\(a=0\\) to deal with some special circumstances. For non-negative function we have two equivalent definition of integration. Definition 2.6 Let \\(f\\) be a non-negative Borel function and define its integral to be \\[\\int f d\\nu=\\underset{\\phi\\in S_f}{\\mbox{sup}} \\int \\phi d\\nu,\\] where \\(S_f\\) is the collection of all non-negative simple function satisfying \\(\\phi(\\omega) \\leq f(\\omega)\\) for any \\(\\omega \\in \\Omega\\). Another definition may be more suitable for operation, which comes from the well known Monotone Convergence Theorem. Definition 2.7 Let \\(f\\) be a non-negative Borel function and define its integral to be \\[\\int f d\\nu=\\lim_{n \\to \\infty} \\int f_n d\\nu,\\] where \\(0 \\leq f_n \\uparrow f\\) for \\(f_n\\) is simple function for all \\(n\\). For general function \\(f\\), its integral is defined as \\[\\int f d\\nu=\\int f_{+} d\\nu-\\int f_{-} d\\nu,\\] we say this integral exists if and only if both integral on the right hand side are finite. Furthermore, we say \\(f\\) is integrable if both integral are finite. Clearly, we have \\(f\\) is integrable if and only if \\(|f|\\) is since \\(|f|=f_{+}+f_{-}\\). Below are some basic proposition: Proposition 2.3 Let \\(f\\) ang \\(g\\) are Borel function. Then If \\(f \\leq g\\) and \\(a \\in \\mathbb{R}\\), then \\(\\int (af)\\, d\\nu\\) exists and is equal to \\(a\\int f \\, d\\nu\\). If both \\(\\int f \\, d\\nu\\) and \\(\\int g \\, d\\nu\\) exist and \\(\\int f \\, d\\nu+\\int g \\, d\\nu\\) is well defined (not \\(\\infty-\\infty\\)), then \\(\\int (f+g) \\, d\\nu\\) exists and is eual to \\(\\int f \\, d\\nu+\\int g \\, d\\nu\\). If \\(f \\leq g\\) a.e., then \\(\\int f \\, d\\nu \\leq \\int g \\, d\\nu\\) if the integrals exist. If \\(f \\geq 0\\) a.e. and \\(\\int f d\\nu =0\\), then \\(f=0\\) a.e. \\(\\nu(A)=0\\) implies that \\(\\int_A f d\\nu =0\\) where \\(\\int_A f d\\nu := \\int fI_A d\\nu\\). Here we also recall some classic theorem about limit and integral without proof in the next proposition. Proposition 2.4 Let \\(f_1, f_2,\\cdots,\\) be a sequence of Borel functions on \\((\\Omega,\\cal F,\\nu)\\). (Monotone convergence theorem). If \\(0 \\leq f_1 \\leq f_2 \\leq \\cdots\\) and \\(\\lim_\\limits{n \\to \\infty} f_n=f\\) a.e., then \\(\\int \\lim_\\limits{n \\to \\infty} f_n d\\nu=\\lim_\\limits{n \\to \\infty} \\int f_n d\\nu\\). (Dominated convergence theorem). If \\(\\lim_\\limits{n \\to \\infty} f_n=f\\) a.e. and there exists an integrable function \\(g\\) such that \\(|f_n| \\leq g\\) a.e., then \\(\\int \\lim_\\limits{n \\to \\infty} f_n d\\nu=\\lim_\\limits{n \\to \\infty} \\int f_n d\\nu\\). (Fatous’s lemma). If \\(f_n \\geq 0\\), then \\(\\int \\lim_\\limits{n \\to \\infty} f_n d\\nu=\\lim_\\limits{n \\to \\infty} \\int f_n d\\nu\\). Example 2.2 Here we consider the interchange of differentiation and integration. That is, for fixed \\(\\theta \\in \\mathbb{R}\\), let \\(f(\\omega, \\theta)\\) be a Borel function on \\((\\Omega,\\cal F,\\nu)\\). Assume that \\(\\partial f(\\omega, \\theta)/\\partial \\theta\\) exists a.e. for \\(\\theta \\in (a,b) \\subset \\mathbb{R}\\) and that \\(|\\partial f(\\omega, \\theta)/\\partial \\theta| \\leq g(\\omega)\\) a.e., where \\(g\\) is an integrable function on \\(\\Omega\\). Then for each \\(\\theta \\in (a,b)\\), \\(\\partial f(\\omega, \\theta)/\\partial \\theta\\) is integrable and by mean value theorem and Dominated convergence theorem, we have \\[\\frac{d}{d\\theta} \\int f(\\omega, \\theta) d\\nu= \\int (\\partial f(\\omega, \\theta)/\\partial \\theta) \\, d\\nu.\\] Example 2.3 Consider the moment generating function of a random variable \\(X\\), \\(M(t)\\) on a finite interval \\((a,b)\\). By the above example and the fact that \\(|x|e^{t_0x} \\leq c_{+} e^{(t_0+\\delta) x}+c_{-} e^{(t_0-\\delta) x}\\), where \\(c_{+}=\\underset{x \\geq 0}{\\max} \\frac{|x|e^{tx}}{e^{(t_0+\\delta)x} }\\) and \\(c_{-}=\\underset{x \\leq 0}{\\max} \\frac{|x|e^{tx}}{e^{(t_0-\\delta)x} }\\) for some \\(t_0 \\in (a,b)\\), then we have \\(M&#39;(t)=E(Xe^{tX})\\). Theorem 2.2 (Change of variables) Let \\(f\\) be measurable from \\((\\Omega,\\cal F,\\nu)\\) to \\((\\Lambda,\\cal G)\\) and \\(g\\) be Borel on \\((\\Lambda,\\cal G)\\). Then \\[\\int_{\\Omega} g(f(\\omega)) d\\nu(\\omega)= \\int_{\\Lambda} g(x) d(\\nu \\circ f^{-1})(x),\\] where \\(\\nu \\circ f^{-1}(B):= \\nu(f^{-1}(B))\\) for \\(B \\in \\cal G\\). Consider an easy case, let \\(g=\\sum_\\limits{i=1}^k c_iI_{A_i}\\) for \\(A_1,\\cdots, A_k\\) disjoint. Then the right hand side is equal to \\(\\sum_\\limits{i=1}^k c_i\\, \\nu\\circ f^{-1}(A_i)\\) and let \\(B_i=f^{-1}(A_i)\\), then the equality holds clearly. An important application of the theorem is that for random variable X with distribution \\(P \\circ X^{-1}\\), we have \\[ E(g(X))=\\int g(X(\\omega)) dP(\\omega)=\\int g(x) dP\\circ X^{-1}(x).\\] Also, by the uniqueness theorem of measure, \\(P\\circ X^{-1}\\) coincides with the cumulative density function \\(F(x):=P(X\\leq x)\\). We also denote \\(P\\circ X^{-1}\\) as \\(P_X\\), the distribution of \\(X\\). Below we consider the interchange of integration which is known as Fubini’s Theorem. Theorem 2.3 (Fubini Theorem) Let \\(\\nu_i\\) be \\(\\sigma\\)-finite measure on \\((\\Omega_i,\\cal F_i)\\) for \\(i=1,2\\), and let \\(f\\) be Borel function on the product \\(\\sigma\\) algebra. Suppose \\(f \\geq 0\\) (w.r.t. Tonelli’s theorem) or \\(f\\) integrable with respect to \\(\\nu_1 \\times \\nu_2\\). Then \\[\\int_{\\Omega_1} f(\\omega_1,\\omega_2) d\\nu_1\\] exists \\(\\nu_2\\)-a.e. and is a Borel function on \\(\\Omega_2\\) whose integral with respect to \\(\\nu_2\\) exists, and \\[\\int_{\\Omega_1 \\times \\Omega_2} f(\\omega_1,\\omega_2)=\\int_{\\Omega_2}(\\int_{\\Omega_1} f(\\omega_1,\\omega_2) d\\nu_1) d\\nu_2.\\] The “\\(\\sigma\\)-finite” condition on the measures is assumed for the uniqueness of \\(\\nu_1 \\times \\nu_2\\). It can be seen necessary if we consider the interchange of integral of an indicator function on which the set is an arbitrary set in the product field. In the following We discuss the coincidence of Riemann integral and Lebesgue integral. An easy result can be shown on finite interval \\((a,b)\\) that Riemann integrability implies Lebesgue integrability and the values of the integrals coincides. That is, \\[\\int_{(a,b)} f d\\lambda=\\int_a^b f(x) dx. \\] Furthermore, we can extend the result to the domain like \\((0,\\infty)\\) for a positive function \\(f\\) by the monotone convergence theorem. We end this chapter by the two classical examples. The first one is used for calculating the expectation of a positvie random variable. Example 2.4 Combining the result of Fubini’s Theorem and the above consequence, we can show that for \\(X&gt; 0\\), \\[E(X)=\\int_0^{\\infty}(1-F(t)) \\, dt.\\] Let the \\(\\lambda\\) be Lebesgue measure, the RHS can be written as \\(\\int_{(0,\\infty)} \\int I_{(t, \\infty)}(x) dP_X(x) \\, d\\lambda(t)\\), then the result follows by applying Fubini’s Theorem. Example 2.5 For function \\(f \\geq 0\\) taken values on \\(\\Omega=(\\omega_1,\\omega_2,\\cdots)\\), by monotone convergence theorem and the fact that \\(f=\\lim_\\limits{n\\to \\infty} \\sum_\\limits{i=1}^n f(\\omega_i)\\) we have \\(\\int f d\\nu= \\sum_i f(\\omega_i)\\nu(\\omega_i)\\). 2.2.2 Radon-Nikodym Derivative Definition 2.8 (absolutely continuous) Given two measures \\(\\mu,\\nu\\) on \\((\\Omega, \\cal F)\\), we say \\(\\mu\\) is absolutely continuous with respect to \\(\\nu\\), denoted by \\(\\mu \\ll \\nu\\), if \\(\\nu(A)=0\\) implies \\(\\mu(A)=0\\) for any \\(A \\in \\cal F\\). Theorem 2.4 (Rando-Nikodym Theorem) Given two measures \\(\\mu,\\nu\\) on \\((\\Omega, \\cal F)\\) and \\(\\nu\\) is \\(\\sigma\\)-fintie. If \\(\\mu \\ll\\nu\\), then there exists a nonnegative Borel function \\(f\\), which is unique \\(\\nu\\)-a.e. on \\(\\Omega\\) such that \\[\\mu(A)=\\int_A f d\\nu.\\] Such function \\(f\\) is called a Rando-Nikodym derivative or density and is denote by \\(\\frac{d\\mu}{d\\nu}\\). A function \\(f\\geq 0\\) \\(\\nu\\)-a.e. is called probabiilty density function (p.d.f.) w.r.t a probabiity measure \\(\\mu\\) if \\(\\int f d\\nu=1\\). A discrete p.d.f. is a p.d.f w.r.t counting measure and a Lebesgue p.d.f corresponds to Lebesgue measure. A sufficient and necessary condition for a c.d.f. \\(F\\) having a Lebesgue p.d.f is that \\(F\\) is absolutely continuous. Below we consider a special case that both Lebesgue p.d.f and discrete p.d.f cannot be well defined. Example 2.6 Suppose that \\(Z\\) is a standard normal r.v. and \\(X=ZI_{[1,\\infty]}(Z)\\), clearly \\(X\\) has no Lebesgue density since \\(P_X({0})\\neq 0\\). Let \\(\\mu\\) be the probability measure on \\((\\mathbb{R},\\cal B)\\) such that \\(\\delta_0(A)=I_A(0)\\). First we claim that \\(P_X \\ll \\delta_0+\\lambda\\) since for any set \\(A\\in \\cal F\\), \\((\\delta_0+\\lambda)(A)=0\\) implies \\(0 \\notin A\\) and \\(\\lambda(A)=0\\). Then \\(P_X(A)=P(Z\\geq 1,Z \\in A)+P(Z&lt;1,Z \\in A)\\stackrel{0\\notin A}=P(Z\\geq 1,Z \\in A)\\stackrel{\\lambda(A)=0}=0,\\) which proves the claim. Secondly, we would like to find out the Radon-Nikodym derivative \\(\\frac{dP_X}{d(\\delta_0+\\lambda)}\\). "],["conditional-expectation.html", "2.3 Conditional Expectation", " 2.3 Conditional Expectation "],["asymptotical-theory.html", "2.4 Asymptotical Theory", " 2.4 Asymptotical Theory "]]
