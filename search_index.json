[["prob.html", "Chapter 2 Measure-based Probability theory", " Chapter 2 Measure-based Probability theory In this chapter, we quickly review the concepts in measure-based probability theory. The measure theory help us rigorously and axiomatically describe the randomness. When it comes to talk about a “probability” of an event, first we have to know about the underlying probability space. "],["probability-spaces-and-random-elements.html", "2.1 Probability Spaces and Random Elements", " 2.1 Probability Spaces and Random Elements 2.1.1 Recap: Measure theory We start from some basic concepts in the classical measure theory and use them to describe the probability space. Definition 2.1 ( \\(\\sigma\\)-algebra) Let \\(\\cal F\\) be a collection of subsets of a sample space \\(\\Omega\\). \\(\\cal F\\) is called a \\(\\sigma\\)-algebra or \\(\\sigma\\)-field on \\(\\Omega\\) if The empty set \\(\\phi \\in \\cal F\\). If \\(A \\in \\cal F\\), then \\(A^c \\in \\cal F\\). If \\(A_i \\in \\cal F\\) for \\(i=1,2,\\cdots\\), then \\(\\cup_{i=1}^{\\infty} A_i \\in \\cal F\\). We denote the smallest sigma algebra containing a collection \\(C\\) as \\(\\sigma(C)\\). In particular, we denote \\(\\cal B= \\sigma(C)\\) the \\(\\sigma\\)-field (called Borel field) where \\(C\\) denotes all finite open interval on \\(\\mathbb{R}\\). By Linderberg’s covering lemma, we can see \\(\\cal B\\) is also the smallest \\(\\sigma\\)-field containing the collection of all open sets on \\(\\mathbb{R}\\). Furthermore, we denote \\(\\cal B^k\\) as the Borel field in \\(\\mathbb{R}^k\\). Define the pair \\((\\Omega, \\cal F)\\) a measurable space if \\(\\cal F\\) is a \\(\\sigma\\)-field on \\(\\Omega\\). Definition 2.2 (Measure) A set function \\(\\nu(\\cdot)\\) defined on a \\(\\sigma\\)-field \\(\\cal F\\) is a measure if \\(0 \\leq \\nu(A) \\leq \\infty\\) for any \\(A \\in \\cal F\\). \\(\\nu(\\phi)=0\\) If \\(A_i \\in \\cal F\\), \\(i=1,2,\\cdots\\) and \\(A_i\\)’s are disjoint for any \\(i\\neq j\\), then \\[\\nu(\\cup_i A_i)=\\sum_i \\nu(A_i)\\] The triple \\((\\Omega, \\cal F, \\nu)\\) is called a measure space and it is called a probability space if \\(\\nu(\\Omega)=1\\). Proposition 2.1 Let \\((\\Omega,\\cal F,\\nu)\\) be a measure space. If \\(A \\subset B \\in \\cal F\\), then \\(\\nu(A)\\leq \\nu (B)\\). For any sequence \\(A_1,A_2,\\cdots \\in \\cal F\\), \\[\\nu(\\cup_i A_i)\\leq \\sum_i \\nu(A_i).\\] If \\(A_1 \\subset A_2 \\subset \\cdots \\in \\cal F\\) (or \\(A_1 \\supset A_2 \\supset \\cdots\\) and \\(\\nu(A_k)&lt;\\infty\\) for some \\(k\\in \\mathbb{N}\\)), then \\[\\nu(\\lim_{k \\to \\infty}A_k)=\\lim_{k\\to \\infty}\\nu(A_k).\\] Below we see some uniqueness theorem about the measure, or the result of the well known Dinkin’s \\(\\pi\\)-\\(\\lambda\\) theorem. Definition 2.3 A collection \\(C\\) of some subsets of \\(\\Omega\\) is a \\(\\pi\\)-system if it is closed under intersection. Definition 2.4 Let \\(C\\) be a collection of some subsets of \\(\\Omega\\). A measure \\(\\mu\\) is \\(\\sigma\\)-finite on \\(C\\) if there exist a sequence of sets \\(\\{A_k\\}\\) in \\(C\\) such that \\(\\Omega=\\cup_k A_k\\) and \\(\\mu(A_K)&lt;\\infty\\) for all \\(k\\). Lebesgue measure is an example of \\(\\sigma\\)-finite measure on \\(\\cal B\\). Since probability measure is always finite, so it is \\(\\sigma\\)-finite. Theorem 2.1 (Theorem 10.3 in Billingsley, 1986) Suppose that \\(\\mu_1\\) and \\(\\mu_2\\) are measures on \\(\\sigma(\\cal P)\\), where \\(\\cal P\\) is a \\(\\pi\\)-system. Suppose they are both \\(\\sigma\\)-finite and agree on \\(\\cal P\\), then they also agree on \\(\\sigma(\\cal P)\\). Example 2.1 Here are some examples using the uniqueness theorem: If \\(\\mu\\) is a measure defined on \\(\\cal B\\) and \\(\\mu([a,b])=b-a\\), then by checking that \\(\\cal P:=\\{[a,b]\\,|-\\infty&lt;a&lt;b&lt;\\infty\\}\\) is a \\(\\pi\\)- system and \\(\\cal B=\\sigma(\\cal P)\\) we can show that \\(\\mu\\) agrees with the Lebesgue measure on \\(\\cal B\\). (Billingsley, pp.225-236, 1986) Given measurable spaces \\((\\Omega_i, \\cal F_i,\\nu_i)_{i=1}^k\\) with \\(\\sigma\\)- finite measures, there exists a unique \\(\\sigma\\)- finite measure on product \\(\\sigma\\)- field \\(\\sigma(\\prod_\\limits{i=1}^k \\cal F_i)\\), which is known as product measure, defined by \\[\\nu_1\\times\\cdots\\times\\nu_k\\,(A_1\\times\\cdots\\times A_k):=\\prod_\\limits{i=1}^k \\nu_i(A_i)\\] for all \\(A_i \\in \\cal F_i,\\,i=1,\\cdots,k\\). 2.1.2 Measurable Functions Definition 2.5 (Measurable functions) Let \\(f\\) be a function from \\((\\Omega,\\cal F)\\) to \\((\\Lambda, \\cal G)\\) (both are measurable spaces). Then \\(f\\) is called a measurable function if \\(f^{-1}(\\cal G) \\subset \\cal F\\), where \\(f^{-1}(\\cal G):=\\{f^{-1}(A)\\,|\\, A\\in \\cal G\\}.\\) In the other words, preimage of any set in \\(\\cal G\\) of a measurable fucntion also lies in \\(\\cal F\\). If \\(\\Lambda=\\mathbb{R}\\) and \\(\\cal G=\\cal B\\), \\(f\\) is called a Borel function. Furthermore, a Borel function defined on a probability space is called a random Variable (a random vector with respect to (\\(\\mathbb{R}^k,\\cal B^k\\))). It is worthy noting that we may not require \\(\\cal F\\) to be the \\(\\sigma\\)- field on which \\(f\\) is measurable. In particular, it is easy to prove that \\(f^{-1}(\\cal G)\\) is also a \\(\\sigma\\)- field. This “smaller \\(\\sigma\\)- field is called \\(\\sigma\\)- field induced by \\(f\\) and we denote it by \\(\\sigma(f)\\). We omit the technical proof of the measurability of a function under fundamental operation such as sup, inf, limsup, liminf. Indicator functions, continuous functions, composition of measurable functions are also measurable functions. Readers can refer to the textbook for the proof. Proposition 2.2 (Approximation property) Suppose that f is measurable from \\((\\Omega,\\cal F)\\) to \\((\\bar{\\mathbb{R}}, \\bar{\\cal B})\\), where \\(\\bar{\\mathbb{R}}\\) is the extended real line with respect to \\(\\bar{\\cal B}\\). First assume \\(f \\geq 0\\), then there exists a positive and monotone sequence of simple functions \\(\\{f_n\\}\\) such that \\(f_n \\to f\\). For general measurable function \\(f\\), consider \\(f=f^{+}-f^{-}\\) for general function \\(f\\) and similar result goes. Below we show a lemma which let us connect two measurable function. Lemma 2.1 (Theorem A.42 in Schervish, 1995) Let \\(Y\\) be measurable from \\((\\Omega,\\cal F)\\) to \\((\\Lambda_Y,\\cal G_Y)\\) and \\(Z\\) be measurable from \\((\\Omega,\\cal F)\\) to \\((\\Lambda_Z,\\cal G_Z)\\). Define \\(T=\\{Y(\\omega),\\omega \\in \\Omega\\} \\subset \\Lambda_Y\\). Then \\(Z\\) is measurable from \\((\\Omega,\\sigma(Y))\\) to \\((\\Lambda_Z,\\cal G_Z)\\) if and only if \\(Z=h \\circ Y\\) for some \\(h\\) that is measurable from \\((T,T\\cap \\cal G_Y)\\) to \\((\\Lambda_Z,\\cal G_Z)\\). Remark: Proof of the “if” side is relatively obvious. (WLOG, we can assume \\(\\Lambda_Y\\) is the range of \\(Y\\).) Proof (only if). At first, we show that for \\(\\omega_1,\\ \\omega_2 \\in \\Omega\\), \\(Y(\\omega_1)=Y(\\omega_2)\\) implies \\(Z(\\omega_1)=Z(\\omega_2)\\). Suppose that \\(Y(\\omega_1)=Y(\\omega_1)=a\\). Since \\(Z\\) is measurable with respect to \\(\\sigma(Y)\\), there exist \\(A \\in \\cal G_Y\\) such that \\(Y^{-1}(A) =Z^{-1}(\\{Z(\\omega_1)\\})\\). Clearly \\(\\omega_1,\\ \\omega_2 \\in Z^{-1}(\\{Z(\\omega_1)\\})\\), thus \\(Z(\\omega_1)=Z(\\omega_2)\\). By this first step, the function \\(h\\) with \\(h(Y(\\omega))=Z(\\omega)\\) is well defined with domain being the range of \\(Y\\). Secondly, we prove such \\(h\\) is measurable with respect to \\(T \\,\\cap\\, \\cal G_Y\\). Given \\(B \\in \\cal G_Z\\), let \\(A\\) be an event in \\(\\cal G_Y\\) such that \\(Y^{-1}(A)=Z^{-1}(B)\\) which exists since \\(Z\\) is measurable with respect to \\(\\sigma(Y)\\), then \\(h\\) is measurable if \\(h^{-1}(B)=A\\,\\cap\\,T\\), where \\(T\\) is the range of \\(Y\\). (\\(h^{-1}(B)\\subset A\\,\\cap\\,T\\)). Given \\(a \\in h^{-1}(B)\\), then \\(h(a) \\in B\\) and \\(a=Y(\\omega)\\) for some \\(\\omega\\in \\Omega\\) (\\(a \\in T\\)) by the domain of \\(h\\), and thus \\(Z(\\omega)=h(Y(\\omega)) \\in B\\), \\(\\omega \\in Z^{-1}(B)=Y^{-1}(A)\\) implies \\(a \\in A\\). (\\(A\\,\\cap\\,T\\subset h^{-1}(B)\\)). Given \\(a \\in A \\cap T\\), \\(a=Y(\\omega) \\in A\\) for some \\(\\omega \\in \\Omega\\), then \\(\\omega \\in Y^{-1}(A)=Z^{-1}(B)\\) and by definition of \\(h\\), \\(h(a)=Z(\\omega)\\in B\\), thus \\(a \\in h^{-1}(B)\\). "],["integration-and-differentiation.html", "2.2 Integration and Differentiation", " 2.2 Integration and Differentiation 2.2.1 Lebesgue integral An usual way to define Lebesgue integral is from simple function to non-negative function by approximation property, then to a general function by an easy decomposition. Let us start from simple function. Assume \\(\\phi=\\sum_\\limits{i=1}^k a_iI_{A_i}\\), \\(A_i\\)’s are disjoint. Then its integral with respect to measure \\(\\nu\\) is \\[\\int \\phi d\\nu=\\sum_\\limits{i=1}^k a_i\\nu(A_i).\\] Clearly \\(A_i\\) is required to be measruable which is equivalent to say \\(\\phi\\) is measurable. It can be seen such integration concept comes from “partition the range” while the Riemann integration comes from partition of the domain. This is also shown in the construction of the approximation property. In particular, we define \\(a\\infty=0\\) when \\(a=0\\) to deal with some special circumstances. For non-negative function we have two equivalent definition of integration. Definition 2.6 Let \\(f\\) be a non-negative Borel function and define its integral to be \\[\\int f d\\nu=\\underset{\\phi\\in S_f}{\\mbox{sup}} \\int \\phi d\\nu,\\] where \\(S_f\\) is the collection of all non-negative simple function satisfying \\(\\phi(\\omega) \\leq f(\\omega)\\) for any \\(\\omega \\in \\Omega\\). Another definition may be more suitable for operation, which comes from the well known Monotone Convergence Theorem. Definition 2.7 Let \\(f\\) be a non-negative Borel function and define its integral to be \\[\\int f d\\nu=\\lim_{n \\to \\infty} \\int f_n d\\nu,\\] where \\(0 \\leq f_n \\uparrow f\\) for \\(f_n\\) is simple function for all \\(n\\). For general function \\(f\\), its integral is defined as \\[\\int f d\\nu=\\int f_{+} d\\nu-\\int f_{-} d\\nu,\\] we say this integral exists if and only if both integral on the right hand side are finite. Furthermore, we say \\(f\\) is integrable if both integral are finite. Clearly, we have \\(f\\) is integrable if and only if \\(|f|\\) is since \\(|f|=f_{+}+f_{-}\\). Below are some basic proposition: Proposition 2.3 Let \\(f\\) ang \\(g\\) are Borel function. Then If \\(f \\leq g\\) and \\(a \\in \\mathbb{R}\\), then \\(\\int (af)\\, d\\nu\\) exists and is equal to \\(a\\int f \\, d\\nu\\). If both \\(\\int f \\, d\\nu\\) and \\(\\int g \\, d\\nu\\) exist and \\(\\int f \\, d\\nu+\\int g \\, d\\nu\\) is well defined (not \\(\\infty-\\infty\\)), then \\(\\int (f+g) \\, d\\nu\\) exists and is eual to \\(\\int f \\, d\\nu+\\int g \\, d\\nu\\). If \\(f \\leq g\\) a.e., then \\(\\int f \\, d\\nu \\leq \\int g \\, d\\nu\\) if the integrals exist. If \\(f \\geq 0\\) a.e. and \\(\\int f d\\nu =0\\), then \\(f=0\\) a.e. \\(\\nu(A)=0\\) implies that \\(\\int_A f d\\nu =0\\) where \\(\\int_A f d\\nu := \\int fI_A d\\nu\\). Here we also recall some classic theorem about limit and integral without proof in the next proposition. Proposition 2.4 Let \\(f_1, f_2,\\cdots,\\) be a sequence of Borel functions on \\((\\Omega,\\cal F,\\nu)\\). (Monotone convergence theorem). If \\(0 \\leq f_1 \\leq f_2 \\leq \\cdots\\) and \\(\\lim_\\limits{n \\to \\infty} f_n=f\\) a.e., then \\(\\int \\lim_\\limits{n \\to \\infty} f_n d\\nu=\\lim_\\limits{n \\to \\infty} \\int f_n d\\nu\\). (Dominated convergence theorem). If \\(\\lim_\\limits{n \\to \\infty} f_n=f\\) a.e. and there exists an integrable function \\(g\\) such that \\(|f_n| \\leq g\\) a.e., then \\(\\int \\lim_\\limits{n \\to \\infty} f_n d\\nu=\\lim_\\limits{n \\to \\infty} \\int f_n d\\nu\\). (Fatous’s lemma). If \\(f_n \\geq 0\\), then \\(\\int \\lim_\\limits{n \\to \\infty} f_n d\\nu=\\lim_\\limits{n \\to \\infty} \\int f_n d\\nu\\). Example 2.2 Here we consider the interchange of differentiation and integration. That is, for fixed \\(\\theta \\in \\mathbb{R}\\), let \\(f(\\omega, \\theta)\\) be a Borel function on \\((\\Omega,\\cal F,\\nu)\\). Assume that \\(\\partial f(\\omega, \\theta)/\\partial \\theta\\) exists a.e. for \\(\\theta \\in (a,b) \\subset \\mathbb{R}\\) and that \\(|\\partial f(\\omega, \\theta)/\\partial \\theta| \\leq g(\\omega)\\) a.e., where \\(g\\) is an integrable function on \\(\\Omega\\). Then for each \\(\\theta \\in (a,b)\\), \\(\\partial f(\\omega, \\theta)/\\partial \\theta\\) is integrable and by mean value theorem and Dominated convergence theorem, we have \\[\\frac{d}{d\\theta} \\int f(\\omega, \\theta) d\\nu= \\int (\\partial f(\\omega, \\theta)/\\partial \\theta) \\, d\\nu.\\] Example 2.3 Consider the moment generating function of a random variable \\(X\\), \\(M(t)\\) on a finite interval \\((a,b)\\). By the above example and the fact that \\(|x|e^{t_0dx} \\leq c_{+} e^{(t_0+\\delta) x}+c_{-} e^{(t_0-\\delta) x}\\), where \\(c_{+}=\\underset{x \\geq 0}{\\max} \\frac{|x|e^{tx}}{e^{(t_0+\\delta)x} }\\) and \\(c_{-}=\\underset{x \\leq 0}{\\max} \\frac{|x|e^{tx}}{e^{(t_0-\\delta)x} }\\) for some \\(t_0 \\in (a,b)\\), then we have \\(M&#39;(t)=E(Xe^{tX})\\). Theorem 2.2 (Change of variables) Let \\(f\\) be measurable from \\((\\Omega,\\cal F,\\nu)\\) to \\((\\Lambda,\\cal G)\\) and \\(g\\) be Borel on \\((\\Lambda,\\cal G)\\). Then \\[\\int_{\\Omega} g(f(\\omega)) d\\nu(\\omega)= \\int_{\\Lambda} g(x) d(\\nu \\circ f^{-1})(x),\\] where \\(\\nu \\circ f^{-1}(B):= \\nu(f^{-1}(B))\\) for \\(B \\in \\cal G\\). Consider an easy case, let \\(g=\\sum_\\limits{i=1}^k c_iI_{A_i}\\) for \\(A_1,\\cdots, A_k\\) disjoint. Then the right hand side is equal to \\(\\sum_\\limits{i=1}^k c_i\\, \\nu\\circ f^{-1}(A_i)\\) and let \\(B_i=f^{-1}(A_i)\\), then the equality holds clearly. An important application of the theorem is that for random variable X with distribution \\(P \\circ X^{-1}\\), we have \\[ E(g(X))=\\int g(X(\\omega)) dP(\\omega)=\\int g(x) dP\\circ X^{-1}(x).\\] Also, by the uniqueness theorem of measure, \\(P\\circ X^{-1}\\) coincides with the cumulative density function \\(F(x):=P(X\\leq x)\\). We also denote \\(P\\circ X^{-1}\\) as \\(P_X\\), the distribution of \\(X\\). Below we consider the interchange of integration which is known as Fubini’s Theorem. Theorem 2.3 (Fubini Theorem) Let \\(\\nu_i\\) be \\(\\sigma\\)-finite measure on \\((\\Omega_i,\\cal F_i)\\) for \\(i=1,2\\), and let \\(f\\) be Borel function on the product \\(\\sigma\\) algebra. Suppose \\(f \\geq 0\\) (w.r.t. Tonelli’s theorem) or \\(f\\) integrable with respect to \\(\\nu_1 \\times \\nu_2\\). Then \\[\\int_{\\Omega_1} f(\\omega_1,\\omega_2) d\\nu_1\\] exists \\(\\nu_2\\)-a.e. and is a Borel function on \\(\\Omega_2\\) whose integral with respect to \\(\\nu_2\\) exists, and \\[\\int_{\\Omega_1 \\times \\Omega_2} f(\\omega_1,\\omega_2) d(\\nu_1\\times \\nu_2)=\\int_{\\Omega_2}(\\int_{\\Omega_1} f(\\omega_1,\\omega_2) d\\nu_1) d\\nu_2.\\] The “\\(\\sigma\\)-finite” condition on the measures is assumed for the uniqueness of \\(\\nu_1 \\times \\nu_2\\). It can be seen necessary if we consider the interchange of integral of an indicator function on which the set is an arbitrary set in the product field. In the following We discuss the coincidence of Riemann integral and Lebesgue integral. An easy result can be shown on finite interval \\((a,b)\\) that Riemann integrability implies Lebesgue integrability and the values of the integrals coincides. That is, \\[\\int_{(a,b)} f d\\lambda=\\int_a^b f(x) dx. \\] Furthermore, we can extend the result to the domain like \\((0,\\infty)\\) for a positive function \\(f\\) by the monotone convergence theorem. We end this chapter by the two classical examples. The first one is used for calculating the expectation of a positvie random variable. Example 2.4 Combining the result of Fubini’s Theorem and the above consequence, we can show that for \\(X&gt; 0\\), \\[E(X)=\\int_0^{\\infty}(1-F(t)) \\, dt.\\] Let the \\(\\lambda\\) be Lebesgue measure, the RHS can be written as \\(\\int_{(0,\\infty)} \\int I_{(t, \\infty)}(x) dP_X(x) \\, d\\lambda(t)\\), then the result follows by applying Fubini’s Theorem. Example 2.5 For function \\(f \\geq 0\\) taken values on \\(\\Omega=(\\omega_1,\\omega_2,\\cdots)\\), by monotone convergence theorem and the fact that \\(f=\\lim_\\limits{n\\to \\infty} \\sum_\\limits{i=1}^n f(\\omega_i)\\) we have \\(\\int f d\\nu= \\sum_i f(\\omega_i)\\nu(\\omega_i)\\). 2.2.2 Radon-Nikodym Derivative Definition 2.8 (absolutely continuous) Given two measures \\(\\mu,\\nu\\) on \\((\\Omega, \\cal F)\\), we say \\(\\mu\\) is absolutely continuous with respect to \\(\\nu\\), denoted by \\(\\mu \\ll \\nu\\), if \\(\\nu(A)=0\\) implies \\(\\mu(A)=0\\) for any \\(A \\in \\cal F\\). Theorem 2.4 (Rando-Nikodym Theorem) Given two measures \\(\\mu,\\nu\\) on \\((\\Omega, \\cal F)\\) and \\(\\nu\\) is \\(\\sigma\\)-fintie. If \\(\\mu \\ll\\nu\\), then there exists a nonnegative Borel function \\(f\\), which is unique \\(\\nu\\)-a.e. on \\(\\Omega\\) such that \\[\\mu(A)=\\int_A f d\\nu.\\] Such function \\(f\\) is called a Rando-Nikodym derivative or density and is denote by \\(\\frac{d\\mu}{d\\nu}\\). A function \\(f\\geq 0\\) \\(\\nu\\)-a.e. is called probabiilty density function (p.d.f.) w.r.t a probabiity measure \\(\\mu\\) if \\(\\int f d\\nu=1\\). A discrete p.d.f. is a p.d.f w.r.t counting measure and a Lebesgue p.d.f corresponds to Lebesgue measure. A sufficient and necessary condition for a c.d.f. \\(F\\) having a Lebesgue p.d.f is that \\(F\\) is absolutely continuous. Below we consider a special case that both Lebesgue p.d.f and discrete p.d.f cannot be well defined. Example 2.6 Suppose that \\(Z\\) is a standard normal r.v. and \\(X=ZI_{[1,\\infty]}(Z)\\), clearly \\(X\\) has no Lebesgue density since \\(P_X({0})\\neq 0\\). Let \\(\\mu\\) be the probability measure on \\((\\mathbb{R},\\cal B)\\) such that \\(\\delta_0(A)=I_A(0)\\). First we claim that \\(P_X \\ll \\delta_0+\\lambda\\) since for any set \\(A\\in \\cal F\\), \\((\\delta_0+\\lambda)(A)=0\\) implies \\(0 \\notin A\\) and \\(\\lambda(A)=0\\). Then \\(P_X(A)=P(Z\\geq 1,Z \\in A)+P(Z&lt;1,Z \\in A)\\stackrel{0\\notin A}=P(Z\\geq 1,Z \\in A)\\stackrel{\\lambda(A)=0}=0,\\) which proves the claim. Secondly, we would like to find out the Radon-Nikodym derivative \\(\\frac{dP_X}{d(\\delta_0+\\lambda)}\\). The density with respect to \\((\\delta_0+\\lambda)\\) can be written as \\(\\Phi(0)I_{\\{0\\}}(x)+\\frac{e^{-\\frac{x^2}{2}}}{\\sqrt{2\\pi}}I_{[1,\\infty)}(x)\\), where \\(\\Phi(x)\\) is the c.d.f of standard normal. Remark. Firstly, It can be noticed that \\[\\int_A f\\, d\\delta_0=\\int f(0)I_{A}(x)\\, d\\delta_0(x)=f(0)I_A(0).\\] The first equality holds since \\(fI_{A}(x)=f(0)I_{A}(x)\\) \\(\\delta_0\\)-a.e. Secondly, for the “overlapping case” such as consider the Randon-Nykodym derivative of \\(ZI_{[1,\\infty)}(z)+2I_{(0,1)}(z)\\), the density is \\(\\phi(x)I_{(1,\\infty)\\setminus \\{2\\}}+P(X=2)I_2(x)+P(X=0)I_0(x)\\). It is important that the set w.r.t first component has to consider minusing \\(\\{2\\}\\). Below we list some propositions regarding to Randon-Nykodym derivative. Proposition 2.5 Let \\(\\nu\\) be a \\(\\sigma\\)-finite measure on a measure space \\((\\Omega,\\cal F)\\). Then If \\(\\lambda\\) is a measure, \\(\\lambda \\ll \\nu\\), and \\(f\\geq 0\\), then \\[\\int f d\\lambda=\\int f\\frac{d\\lambda}{d\\nu} d\\nu\\] If \\(\\lambda_i\\ll \\nu\\) for \\(i=1,2\\), then \\(\\lambda_1+\\lambda_2\\ll \\nu\\) and \\[\\frac{d(\\lambda_1+\\lambda_2)}{d\\nu}=\\frac{d\\lambda_1}{d\\nu}+\\frac{d\\lambda_2}{d\\nu} \\quad \\nu\\mbox{-a.e.}\\] If \\(\\tau\\) is a measure, \\(\\lambda\\) is a \\(\\sigma\\)-finite measure, and \\(\\tau\\ll\\lambda\\ll \\nu\\), then \\[\\frac{d\\tau}{d\\nu}=\\frac{d\\tau}{d\\lambda}\\frac{d\\lambda}{d\\nu}\\quad \\nu\\mbox{-a.e.}\\] In particular, if \\(\\lambda\\ll \\nu\\) and \\(\\nu \\ll \\lambda\\) (equivalent), then \\(\\frac{d\\lambda}{d\\nu}=(\\frac{d\\nu}{d\\lambda})^{-1}\\). The first result can be quickly verified by utilizing the approximation property and Monotone Convergence Theorem. The third result (chain rule) can be directly obtained by the first one. Below we consider the density of transformation of random variables. A general result is given in proposition 1.8 of the textbook. Example 2.7 Suppose that \\(X\\) is a random variable with Lebesgue p.d.f. \\(f_X\\) and \\(f_X(x)=0\\) for \\(x\\leq 0\\). Let \\(Y=X^2\\) and \\[g(y)=(2\\sqrt{y})^{-1}f_X(\\sqrt{y})I_{(0,\\infty)}(y).\\] Then \\(g\\) is a Lebesgue p.d.f. of \\(Y\\). To verify the above result, i.e. we want \\(P(Y\\in A)=\\int_A g(y) d\\lambda(y)\\) for \\(A \\in \\cal B(\\mathbb{R})\\). It suffices to consider the case of intervals like \\((-\\infty,b]\\) (a \\(\\pi\\)-system) and let \\(\\lambda^{+}(A):=\\int_A I_{(0,\\infty)}(y) d\\lambda(y)\\) (\\(\\frac{d\\lambda^{+}}{d\\lambda}(y)=I_{(0,\\infty)}(y)\\)) and \\(h(y)=\\sqrt{y}I_{(0,\\infty)}(y)\\). Then for \\(b&gt;0\\), \\[\\begin{split} \\int_{(-\\infty,b]} g(y) d\\lambda(y)&amp;=\\int_{(-\\infty,b]} (2\\sqrt{y})^{-1}f_X(\\sqrt{y})I_{(0,\\infty)}(y) d\\lambda(y) \\\\ &amp;= \\int_{(-\\infty,b]} (2\\sqrt{y})^{-1}f_X(\\sqrt{y}) \\frac{d\\lambda^{+}}{d\\lambda}(y) d\\lambda(y) \\\\ &amp;=\\int I_{(0,b)}(y) (2\\sqrt{y})^{-1}f_X(\\sqrt{y}) d\\lambda^{+}(y)\\\\ &amp;=\\int I_{(0,\\sqrt{b})}(z) (2z)^{-1}f_X(z) d(\\lambda^{+}\\circ h^{-1})(z). \\end{split}\\] Note that \\[\\lambda^{+}\\circ h^{-1}((-\\infty,b))=\\lambda^{+}((0,b^2))=b^2=\\int_{(-\\infty,b)}2xI_{(0,\\infty)}(x) d\\lambda(x).\\] Thus \\[\\frac{d\\lambda^{+}\\circ h^{-1}}{d\\lambda}(x)=2xI_{(0,\\infty)}(x).\\] Therefore by applying the first one in proposition 2.5 again, we can derive that \\[\\int_{(-\\infty,b]} g(y) d\\lambda(y)=\\int_{(0,\\sqrt{b})}f_X(z) d\\lambda(z)=P_X((0,\\sqrt{b}))=P(Y\\in (0,b]).\\] For the case \\(f_x \\neq 0\\) on \\((-\\infty,0)\\), the RN (Radon-Nykodim derivative) is \\[ f_Y(y)=(\\frac{f_x(\\sqrt y)}{(2\\sqrt y)}+\\frac{f_x(-\\sqrt y)}{(2\\sqrt y)})I_{(0,\\infty)}(y).\\] In summary, the proof is mainly based on (i) the change of measure and (ii) the integral formula w.r.t change of variables. Remark. Can the result above be generalized to a general measure other than Lebesgue measure? "],["conditional-expectation.html", "2.3 Conditional Expectation", " 2.3 Conditional Expectation 2.3.1 Conditional Expectation Definition 2.9 Let \\(X\\) be a integrable random variable on \\((\\Omega, \\cal F,P)\\). Let \\(\\cal A\\) be a sub \\(\\sigma\\)-field of \\(\\cal F\\). The condition expectation of \\(X\\) given \\(\\cal A\\) (which we denote it as \\(E(X|\\cal A)\\)) is the a.s.-unique random variable satisfying \\(E(X|\\cal A)\\) is measurable from \\((\\Omega,\\cal A)\\) to \\((R,\\cal B)\\) and \\(\\int_A E(X|\\cal A) \\rm dP=\\) \\(\\int_{A} X dP\\) for all \\(A \\in \\cal A\\). Let \\(B \\in \\cal F\\). The conditional probability of \\(B\\) given \\(\\cal A\\) is defined to be \\(P(B|\\cal{A})=\\) \\(E(I_B|\\cal A)\\). Let \\(Y\\) be measurable from \\((\\Omega, \\cal F,P)\\) to \\((\\Lambda, \\cal G)\\). The conditional expectation of \\(X\\) given \\(Y\\) is defined to be \\(E(X|Y)=E(X|\\sigma(Y)).\\) Define \\(\\mu^{+}=\\int_A X^{+} dP\\) for \\(A \\in \\cal A\\), then such \\(\\mu^{+}\\) is a measure on \\(\\cal A\\). Let \\(P_0\\) be the restriction of \\(P\\) on \\(\\cal A\\). Then clearly we have \\(\\mu^{+}\\ll P_0\\). It is easy to check that \\(E(X^{+}|\\cal A)= \\frac{d\\mu^{+}}{dP_0}\\) and \\(E(X^{-}|\\cal A)= \\frac{d\\mu^{-}}{dP_0}\\) (by similarly defining \\(\\mu^{-}\\)) will satisfy the definition of conditional expectation. The uniqueness and existence follows by RN theorem. Example 2.8 Suppose \\(\\Omega={1,2,3,4}\\) and \\(P(\\{k\\})=\\frac{1}{4}\\) for \\(k\\in\\Omega\\). Suppose that \\(X(k)=k\\) for \\(k\\in\\Omega\\). Let \\(Y(1)=4,\\ Y(2)=5,\\ Y(3)=Y(4)=6\\). Find \\(E(X|\\sigma(Y))=h(Y)\\). Directly by calculating that \\(\\int_A E(X|\\cal A) \\rm dP=\\) \\(\\int_{A} X dP\\), we can derive that \\(h(4)=1,\\ h(5)=2,\\ h(6)=\\frac{7}{2}\\). If we consider trivial \\(\\sigma\\)-algebra \\(\\cal A=\\{\\phi,\\ \\Omega\\}\\), then by measurability we know that \\(E(X|\\cal A)\\) must be a constant function. By the integral restriction, clearly \\(E(X|\\cal A)=\\rm E(X)\\). Furthermore, suppose \\(X\\) is measurable w.r.t \\(\\cal A_0\\) which is a sub \\(\\sigma\\)-field of \\(\\cal A\\). Then \\(E(X|\\cal A)=\\rm X\\). Note that \\(E(X|\\sigma(Y))=E(X|Y)=h(Y)\\) for some \\(h\\) by lemma 2.1. Thus we may write \\(E(X|Y=y)=h(y)\\). Below we give some proposition regarding to conditoinal expectation. Proposition 2.6 Given the same setup above, we have If \\(X=c\\) a.s. for \\(c \\in \\mathbb{R}\\) then \\(E(X|\\cal A)=c\\) a.s. (measurability is trivial for a constant function). If \\(X\\leq Y\\) a.s., then \\(E(X|\\cal A)\\leq \\rm E(Y|\\cal A)\\) a.s. (which can be quickly proved by linearity) For \\(E|X|,\\ E|Y|&lt; \\infty\\), \\(E(aX+bY|\\cal A)=a\\rm E(X|\\cal A)+b\\rm E(Y|\\cal A)\\). \\(E(E(X|\\cal A))= \\int_{\\Omega} \\rm E(X|\\cal A) \\rm dP=\\int_{\\Omega} X dP=E(X)\\). Let \\(\\cal A_0 \\subset \\cal A\\) be sub \\(\\sigma\\)-fields of some \\(\\cal F\\). Then \\(E(E(X|\\cal A)|\\cal A_0))=\\rm E(\\rm E(X|\\cal A_0)|\\cal A))=\\rm E(X|\\cal A_0)\\). If \\(\\sigma(Y)\\subset \\cal A\\) and \\(E(|XY|)&lt; \\infty\\), then \\(E(XY|\\cal A)=\\rm YE(X|\\cal A)\\). Suppose \\(X\\) and \\(Y\\) are independent, \\(g\\) is Borel function and \\(E|g(X,Y)|&lt;\\infty\\). Let \\(h(y)=E(g(X,y))\\) for all \\(y \\in Y\\). Then \\(E(g(X,Y)|Y)=h(Y)\\), or equivalently, \\(E(g(X,Y)|Y=y)=h(y)\\). If \\(E(X^2)&lt; \\infty\\), then \\([E(X|\\cal A)]^2\\leq \\rm E(X^2|\\cal A)\\) a.s. Remark. We briefly discuss how to show some of the properties as following: For 6. we start from considering \\(Y\\) is a simple function and use LDCT on general measurable \\(Y\\). For 7. let \\(g(X,Y)=I_A(X)I_B(Y)\\), then \\(\\int_C h(y)dP_Y(y)=P(X\\in A)P(Y\\in B\\cap C)\\). On the other hand, \\(\\int_C I_A(X)I_B(Y) dP_Y(y)=P(X\\in A, Y\\in B\\cap C)\\), so the result follows by independence. For 8., we directly show that by \\(0 \\leq E[X-E(X|\\cal A)^2|\\cal A]=\\rm E(X^2|\\cal A)- \\rm (E(X|\\cal A))^2\\). The equality follows by linearity and 6. Example 2.9 This example shows that \\(E(X|\\cal A)\\) is the best guess of \\(X\\) given some knowledge of \\(\\cal A\\), which means \\[\\int (X-E(X|\\cal A))^2 \\rm dP\\leq \\int (X-Y)^2 \\rm dP\\] for any \\(Y\\) measurable w.r.t. \\(\\cal A\\). Let \\(Z=Y-E(X|\\cal A)\\) measurable w.r.t. \\(\\cal A\\). It follows by that \\(\\int Z(X-E(X|\\cal A)) \\rm dP=E(E(Z(X-E(X|\\cal A))|\\cal A))=0\\). 2.3.2 Independence First we extend the definition of independence to \\(\\sigma\\)-algebra. Let \\((\\Omega,\\cal F,P)\\) be a probability space. Let \\(\\cal C\\) be a collection of subsets in \\(\\cal F\\). Events in \\(\\cal C\\) is said to be independent if for any \\(n \\in \\mathbb{N}\\) and distinct events \\(A_1,\\cdots,A_n\\) in \\(\\cal C\\), we have \\(P(A_1\\cap\\cdots A_n)=\\prod_{i=1}^n P(A_i)\\). Collections \\(\\cal C_i\\subset \\cal F,\\, i\\in I\\) are said to be independent if events in any collection of the form \\(\\{A_i\\in\\cal C_i:i\\in I\\}\\) are independent. Random elements \\(X_i\\) are independent if \\(\\sigma(X_i)\\) are independent. Suppose that \\(X\\) is a random variable on \\((\\Omega,\\cal F,P)\\) with finite moment and \\(\\cal A_1\\) and \\(\\cal A_2\\) are sub \\(\\sigma\\)-fields of \\(\\cal F\\). If \\(\\sigma(\\sigma(X)\\cup\\cal A_1)\\) and \\(\\cal A_2\\) are independent, then \\[E(X|\\sigma(\\cal A_1\\cup \\cal A_2))=\\rm E(X|\\cal A_1)\\quad a.s.\\] In fact, it is sufficient to show that \\[\\int_{\\cal A_1\\cap \\cal A_1}E(X|\\cal A_1)\\rm dP= \\int_{\\cal A_1\\cap \\cal A_1}X dP.\\] for any \\(A_1\\in \\cal A_1\\) and \\(A_2\\in \\cal A_2\\) since \\(\\mathbb{C}=\\rm \\{A_1\\cap A_2| A_1\\in \\cal A_1,A_2\\in \\cal A_2\\}\\) is a \\(\\pi\\)-system and \\(\\sigma(\\mathbb{C})=\\sigma(\\cal A_1\\cup \\cal A_2)\\). This result can be further established by the fact that \\(E(E(X|A_1) I_{A_2})=\\rm E(X|A_1)P(A_2)\\) given the assumption. As a special case, \\(E(X|Y_1,Y_2)=E(X|Y_1)\\) if \\((X,Y_1)\\) and \\(Y_2\\) are independent by the result of the exercise below (by replacing \\(\\cal A_1\\), \\(\\cal A_2\\) with \\(\\sigma(Y_1)\\) and \\(\\sigma(Y_2)\\)). It still holds if replacing the random variable \\(X\\) with \\(h(X)\\) for any Borel function \\(h\\). In particular, with taking \\(h\\) as indicator function, we have \\[P(A|Y_1,Y_2)=P(A|Y_1)\\] for any \\(A\\in \\sigma(X)\\) if \\((X,Y_1)\\) and \\(Y_2\\) are independent. In such case, we say \\(X\\) and \\(Y_2\\) are conditionally independent given non-constant \\(Y_1\\). Also, if \\(E|X|&lt;\\infty\\), \\(\\sigma(X)\\) and \\(\\sigma(Y)\\) are independent, then \\(E(X|Y)=E(X)\\) a.s. Exercise 2.1 Let \\(Z=(Y_1,Y_2)\\), \\(\\sigma(Z)\\stackrel{?}=\\sigma(\\sigma(Y_1)\\cup\\sigma(Y_2))\\). First we show that \\[\\sigma(\\sigma(Y_1)\\cup\\sigma(Y_2))=\\sigma(\\{Y_1^{-1}(B_1)\\cap\\sigma(Y_2^{-1}(B_2)):B_1\\in \\cal B^n, \\rm B_2\\in \\cal B^m\\}).\\] Then the result follows if \\[\\sigma(Z)=\\sigma(\\{Y_1^{-1}(B_1)\\cap\\sigma(Y_2^{-1}(B_2)):B_1\\in \\cal B^n, \\rm B_2\\in \\cal B^m\\}).\\] For the first equality, notice that \\(\\subseteq\\)-direction is clear since both \\(\\sigma(Y_1)\\) and \\(\\sigma(Y_2)\\) lie in the \\(\\sigma\\)-field on the right hand side. For another direction, note that for any \\(B_1\\) and \\(B_2\\), \\(Y_i^{-1}(B_i) \\in \\sigma(Y_1)\\cup \\sigma(Y_2),\\, i=1,2\\), thus the intersection must lie in the \\(\\sigma\\)-field on the left hand side. For second equality, the \\(\\supseteq\\)-direction is obvious since the set \\(\\mathbb{D}:=\\{Y_1^{-1}(B_1)\\cap\\sigma(Y_2^{-1}(B_2)):B_1\\in \\cal B^n, \\rm B_2\\in \\cal B^m\\}\\) is just \\(\\{Z^{-1}(B_1\\times B_2):B_1\\in \\cal B^n, \\rm B_2\\in \\cal B^m\\}\\). For another direction, note that for \\(\\cal B^{n+m}=\\sigma(\\cal B^n\\times \\cal B^m)\\) and the fact that \\(Z^{-1}(\\sigma(\\mathbb{D})) \\subseteq \\sigma(Z^{-1}(\\mathbb{D}))\\) (in fact, they are equal). The fact can be shown by proving the set \\(\\cal E:=\\{\\rm A| Z^{-1}(A)\\in \\sigma(Z^{-1}(\\mathbb{D}))\\}\\) is a \\(\\sigma\\)-field including the collection \\(\\mathbb{D}\\). Then the result follows from \\(\\sigma(\\mathbb{D})\\subseteq \\cal E\\). 2.3.3 Conditional Distribution First we define \\(\\mu(B,Y)=E(I_B(X)|Y)\\). In other words, \\(\\int_{Y^{-1}(C)} \\mu(B,Y)dP=\\int_{Y^{-1}(C)} I_B(X)dP\\). Furthermore, If \\[\\int I_C(y)[\\int_B f_{X|Y=y}(x) d\\mu(x)]dP_Y(y)=P((X,Y)\\in B\\times C)\\] for \\(B\\in \\cal B_X\\) and \\(C \\in \\cal B_\\rm{Y}\\), then we say \\(f_{X|Y=y}(x)\\) is the conditional density of \\(X\\) given \\(Y=y\\) w.r.t \\(\\mu\\). In fact, such function \\(\\mu(B,Y)\\) is called a random probability measure. Suppose \\((X,Y)\\) has a joint density function \\(f_{X,Y}\\) w.r.t \\(\\mu \\times \\nu\\). First of all, we show the result (\\(f_{X|Y=y}(x)\\) is the conditional pdf w.r.t. \\(\\mu\\)) in basic probability that the conditional can be written as joint over marginal. Let \\(f_{X|Y=y}(x)=\\frac{f_{X,Y}(x,y)}{f_Y(y)}\\) for \\(f_Y\\) is marginal pdf w.r.t. \\(\\nu\\). The result can be validated by \\[\\int I_C(y)(\\int_B \\frac{f_{X,Y}(x,y)}{f_Y(y)}\\, d\\mu(x))dP_Y(y)=\\int_{B\\times C }f_{X,Y}(x,y) d(\\mu\\times \\nu)(x,y).\\] On the contrary, let \\(g(x,y)=f_{X|Y=y}(x)f_Y(y),\\) then \\(g\\) is the pdf of \\((X,Y)\\) w.r.t. \\(\\mu\\times \\nu\\). In other words, we would like to show that \\[\\int_{B\\times C} g(x,y)\\, d(\\mu\\times \\nu)(x,y)=P((X,Y)\\in B\\times C)\\] for \\(B\\in \\cal B^m\\) and \\(C\\in \\cal B^n\\). Indeed, the result directly follows the definition of conditional pdf and density of \\(Y\\). Secondly, we would like to show if \\(E(X|Y=y)=\\int xf_{X|Y=y}(x) d\\mu(x)\\). In other words, we may validate that \\[E[XI_C(y)]=\\int I_C(y) [\\int xf_{X|Y=y}(x) d\\mu(x)] dP_Y(y),\\] by the definition, which can be quickly proved by approximating \\(X\\) with simple functions. Example 2.10 Consider a simple case for Bayesian variable selection as the following, \\((X_{i1},X_{i2},Y_i):=\\cal D\\) which is i.i.d. random sample given \\((a_1,a_2)\\) and follows the model \\(Y=a_1X_1+a_2X_2+\\epsilon\\), where \\((X_1,X_2,\\epsilon)\\) are assumed to be mutually independent. \\(X_1,X_2\\) has density \\(f_1\\) and \\(f_2\\) w.r.t \\(\\lambda\\) given \\((a_1,a_2)\\), also assume \\(\\epsilon \\sim N(0,\\sigma^2)\\) for some \\(\\sigma&gt;0\\). In particular, we put prior \\(\\pi_1\\times \\pi_1\\) on \\((a_1,a_2)\\) with \\(\\pi_1\\)’s density being \\[f_0:=\\frac{d\\pi_1(a)}{d(\\lambda+\\mu_0)}=c_0I_{\\{0\\}}(a)+(1-c_0)\\phi(a)I_{\\{0\\}^c}(a)\\] w.r.t. measure \\((\\lambda+\\mu_0)\\), where \\(\\phi(a)\\) denotes the density of standard normal, \\(\\lambda\\) is Lebesgue measure, \\(\\mu_0\\) is point mass measure on \\(0\\) and \\(c_0\\in(0,1)\\). Calculate the corresponding posterior. Let \\(\\phi_{\\sigma}\\) be the pdf of \\(N(0,\\sigma^2)\\). Clearly the joint density of \\((\\cal D,a_1,a_2)\\) is \\[\\prod_{i=1}^n\\, \\phi_{\\sigma}(y_i-(a_1x_{1,i}+a_2x_{2,i}))f_1(x_{1,i})f_2(x_{2,i})f_0(a_1)f_0(a_2):=h(a_1,a_2)c(\\tilde{x})\\] w.r.t \\(\\lambda^3\\times (\\lambda+\\mu_0)^2\\). In addition, the marginal density of \\(\\cal D\\) can be calculated by \\[c(\\tilde{x})(\\int\\int h(a_1,a_2) d\\mu_0(a_1)d\\mu_0(a_2)+ \\int\\int h(a_1,a_2) d\\lambda(a_1)d\\lambda(a_2)).\\] We omit the detailed calculation of marginal here. (In particular, note that \\(\\int g(a) d\\mu_0(a)=g(0)\\).) Denote the posterior density as \\(f_3\\). Remarkably, the posterior probability of \\((a_1,a_2)=(0,0)\\) is \\[\\tilde{\\pi}((a_1,a_2)=(0,0))=\\int_{(0,0)} f_3(a_1,a_2)d((\\lambda+\\mu_0)\\times(\\lambda+\\mu_0))(a_1,a_2)=f_3(0,0).\\] Similarly, the posterior probability of \\(a_1=0\\) (or \\(a_2=0\\)) can be also derived. Finally, we consider a more general case when joint pdf may not exist with respect to product measure in the above scenario (\\((X,Y)\\)). An application for such consideration is factorization theorem for finding sufficient statistics. For instance, suppose that \\((X,Y)\\)’s distribution has pdf \\(f_{X,Y}\\) w.r.t. \\(P_{X_0,Y_0}\\) for some \\((X_0,Y_0)\\) (dim(\\(X\\))=dim(\\(X_0\\)) and dim(\\(Y\\))=dim(\\(Y_0\\))). Let \\[ f_Y(y)=\\int f_{X,Y}(x,y) dP_{X_0|Y_0=y}(x),\\] then \\(f_Y\\) is a pdf of \\(Y\\) w.r.t. \\(P_{Y_0}\\). In other words, we can verify that \\[P(Y\\in B)=\\int I_B(y)\\int f_{X,Y}(x,y) dP_{X_0|Y_0=y}(x) dP_{Y_0}(y).\\] Indeed, (from the exercise below) the right hand side of the equality can be written as \\[E[I_B(Y_0)f_{X,Y}(X_0,Y_0)]=\\int I_B(y)f_{X,Y}(x,y) dP_{X_0,Y_0}(x,y)=P(Y\\in B),\\] since \\(f_{X,Y}\\) is the pdf w.r.t. \\(P_{X_0,Y_0}\\). Next, we can check that \\(f_{X|Y=y}(y)=\\frac{f_{X,Y}(x,y)}{f_Y(y)}\\) is the conditional pdf of \\(X\\) given \\(Y\\) w.r.t. \\(P_{X_0|Y_0=y}\\). That is to say, we shall validate (which is clear) \\[\\int_C \\int _B \\frac{f_{X,Y}(x,y)}{f_Y(y)} dP_{X_0|Y_0=y}(x) f_Y(y) dP_{Y_0}(y)= P((X,Y)\\in B\\times C).\\] Exercise 2.2 Let \\(g(x,y)=\\sum_i a_i I_{B_i}(x)I_{C_i}(y)\\) (an approximation to a Borel function), prove that \\(\\int g(x,y) dP_{X_0|Y_0=y}(x)=E(g(X_0,Y_0)|Y_0=y)\\). Since \\[ \\int\\sum_i a_iI_{C_i}(y) I_{B_i}(x) dP_{X_0|Y_0=y}(x)= E(\\sum_i a_iI_{C_i}(Y_0)I_{B_i}(X_0)|Y_0=y),\\] which is directly \\(E(g(X_0,Y_0)|Y_0=y)\\). Example 2.11 Let \\(X:=(X_1,\\cdots,X_n)\\) i.i.d from \\(N(\\mu,1)\\) and \\(Y:=(Y_1,\\cdots,Y_n)\\) i.i.d. from \\(N(0,1)\\). It can be seen that \\((X,\\bar{X})\\)’s distribution does not have density w.r.t. product Lebesgue measure. Instead, we can consider the density of \\((X,\\bar{X})\\) w.r.t. \\(P(Y,\\bar{Y})\\). First we may show that \\(P_{X,\\bar{X}}\\ll P_{Y,\\bar{Y}}\\). If we define a transformation \\[T(y_1,\\cdots,y_n)=((y_1,\\cdots,y_n),\\frac{\\sum_i y_i}{n}).\\] Then \\[P_{Y,\\bar{Y}}(A)=P(Y\\in T^{-1}(A))=P_Y(T^{-1}(A))=0,\\] implies \\(\\lambda^n(T^{-1}(A))=0\\). Similarly we can argue \\[P_{X,\\bar{X}}(A)=P_X(T^{-1}(A))=0.\\] Thus \\(P_{X,\\bar{X}}\\ll P_{Y,\\bar{Y}}\\). Secondly, we claim that \\(\\frac{dP_X}{dP_Y}\\) is the density of \\((X,\\bar{X})\\) w.r.t. \\(P_{Y,\\bar{Y}}\\), where \\(\\frac{dP_X}{dP_Y}:=\\frac{\\frac{dP_X}{d\\lambda^n}}{\\frac{dP_Y}{d\\lambda^n}}\\). That is to say, we need to verify that \\[\\int_{A\\times B}\\frac{dP_X}{dP_Y}(x)dP_{Y,\\bar{Y}}(x,s)=P_{X,\\bar{X}}(A\\times B).\\] The LHS can be written as \\(E[I_A(Y)I_B(\\bar{Y})\\frac{dP_X}{dP_Y}(Y)]\\), which turns out to be \\[E[I_{T^{-1}(A\\times B)}(Y)\\frac{dP_X}{dP_Y}(Y)].\\] On the other hand, the RHS is just \\(P_X(T^{-1}(A\\times B))\\), which is \\[P_X(T^{-1}(A\\times B))=\\int I_{T^{-1}(A\\times B)}\\frac{dP_X}{dP_Y}(y)dP_Y(y).\\] Therefore, the LHS agrees on RHS. Lastly, we would like to write down the conditional probability. Since the joint density is given above. It remains to calculate the marginal density, that is, \\[f_{\\bar{X}}(s)=\\int f_{X,\\bar{X}}(x,s) dP_{Y|\\bar{Y}=s}(x)\\] w.r.t. \\(P_{\\bar{Y}}\\). The key observation here is the joint density \\(\\frac{dP_X}{dP_Y}\\) can be written as \\[\\frac{dP_X}{dP_Y}=e^{-\\frac{(n(\\bar{X}-\\mu)^2+n\\bar{X}^2)}{2}},\\] which is a function only dependent on \\(\\bar{X}\\) and parameter \\(\\mu\\). Furthermore, the marginal density of \\(\\bar{X}\\) w.r.t. \\(P_{Y|\\bar{Y}=s}\\) is \\[\\int \\frac{dP_X}{dP_Y}(x) dP_{Y|\\bar{Y}=s}(x)=e^{-\\frac{(n(s-\\mu)^2+ns^2)}{2}}.\\] Therefore the conditional density is \\(1\\). In particular, recall the definition of sufficient statistics. The result shows that \\(\\bar{X}\\) is indeed the sufficient statistic of \\(\\mu\\). Example 2.12 Below we see a generalization of the result in the last example. See lemma 2.1 in the textbook. Let \\(X=(X_1,\\cdots,X_n)\\) with \\(P_X\\in\\{P_{\\theta}:\\theta \\in \\Theta\\}\\) has dominating \\(\\sigma\\)-finite measure \\(\\nu\\). Denote the pdf of \\(X\\) as \\(f_\\theta\\) w.r.t \\(\\nu\\). There exist \\(\\{c_i\\}_{i=1}^\\infty\\) sequence of positive numbers and \\(\\{\\theta_i\\}_{i=1}^\\infty\\) sequence in \\(\\cal \\Theta\\) such that \\(\\sum_i c_i=1\\) and \\(P_\\theta \\ll \\sum c_iP_{\\theta_i}\\) for all \\(\\theta \\in \\cal \\Theta\\). There exists a random variable \\(X_0\\) such that \\(P_{X_0}=\\sum_i c_iP_{\\theta_i}\\). Furthermore, by MCT we can show \\[\\frac{dP_{X_0}}{d\\nu}=\\sum_i c_i\\frac{dP_{\\theta_i}}{d\\nu}=\\sum_i c_i f_{\\theta_i}.\\] Hence we have \\[\\frac{dP_\\theta}{dP_{X_0}}=\\frac{f_{\\theta}}{\\sum_i c_i f_{\\theta_i}}.\\] Then part side of the factorization theorem tells us that \\(f_\\theta(x)=g(\\theta,T(x))h(x)\\) implies \\(T(X)\\) is sufficient for \\(P_X\\). That is to say, it requires to show that \\(P_{X|T(X)=s}\\) is independent of \\(\\theta\\). Similarly, the first step is to show that \\[\\frac{dP_{X,T(X)}}{dP_{X_0,T(X_0)}}=\\frac{dP_{X}}{dP_{X_0}}=\\frac{f_{\\theta}}{\\sum_i c_i f_{\\theta_i}}.\\] Then the result immediately follows by the condition and the same argument. Remark. In the proof of lemma 2.1, the author (Jun Shao) merely considered the case of finite measure \\(\\nu\\). In fact, for a \\(\\sigma\\)-finite measure \\(\\nu\\), we can find a finite measure \\(\\mu\\) (or a probability measure) that dominates \\(\\nu\\). To show that, since \\(\\nu\\) is \\(\\sigma\\)-finite, we can find \\(E_k\\) with finite measure such that \\(\\cup_k E_k\\) is the whole measurable space. Then the fact follows by defining \\[\\mu(A)=\\sum_{k=1}^\\infty \\frac{\\nu(A\\cap E_k)}{2^k\\nu(E_k)}\\] for any \\(A\\) in the corresponding \\(\\sigma\\)-algebra. Thus it suffices to consider the case of finite measure. 2.3.4 Markov chains and Martingales Definition 2.10 A sequence of random vectors \\(\\{X_n:n\\in\\mathbb{N}\\}\\) is said to be a (discrete time) Markov chain or Markov process if \\[P(B|X_1,\\cdots,X_n)=P(B|X_n) \\quad \\mbox{a.s.}\\] for any \\(B\\in \\sigma(X_{n+1}), n=2,3,\\cdots\\) It can be seen that for a Markov chain \\(\\{X_n\\}\\), \\(X_{n+1}\\) is conditionally independent of \\((X_1,\\cdots,X_{n-1})\\) given \\(X_n\\). We will list some equivalent conditions of Markov chain without proving below. Proposition 2.7 A sequence of random vectors \\(X_n\\) is a Markov chain if and only if any one of the following three conditions holds. For any integrable \\(h(X_{n+1})\\) with Borel function \\(h\\), \\(E[h(X_{n+1})|X_1,\\cdots,X_n]=E[h(X_{n+1})|X_n]\\) a.s. for \\(n\\geq 2\\). \\(P(B|X_1,\\cdots,X_n)=P(B|X_n)\\) a.s. for \\(n\\in \\mathbb{N}\\) and \\(B\\in \\sigma(X_{n+1},X_{n+2},\\cdots)\\). For any \\(n\\geq 2\\), \\(A\\in \\sigma(X_1,\\cdots,X_n)\\), and \\(B\\in \\sigma(X_{n+1},X_{n+2},\\cdots)\\), \\(P(A\\cap B|X_n)=P(A|X_n)P(B|X_n)\\) a.s. Further properties(periodic, invariant, irreducible, etc.) and applications of Markov chains like MCMC can be referred to chapter 4 in the textbook. Thereafter, we introduce martingale which is quite important in stochastic process and financial applications. Current studies of sequential analysis and game-theoretic statistics are also strongly connected with this topic. Definition 2.11 The sequence of \\(\\{X_n,\\cal F_n\\}\\) with \\(X_n\\) being a sequence of random variables defined on on a probability space \\((\\Omega, \\cal F, P)\\) and \\(\\cal F_1\\subset F_2\\subset \\cdots \\subset F\\) being a sequence of \\(\\sigma\\)-fields (called a ``filtration’’) such that \\(\\sigma(X_n)\\subset \\cal F_n\\) is said to be a martingale if \\[E(X_{n+1}|\\cal F_n)=\\rm X_n \\quad \\mbox{a.s.}\\] for all \\(n\\in \\mathbb{N}\\). Furthermore, \\(\\{X_n,\\cal F_n\\}\\) is said to be a submartingale (supermartingale) if the “\\(=\\)” of the formula is replaced by “\\(\\geq\\)” (or “\\(\\leq\\)”). We can derive that for a martingale \\(X_n\\) (i) \\(E(X_{n+j}|\\cal F_n)=\\rm X_n\\) a.s. ,and (ii) \\(EX_1=EX_j\\) for all \\(j=1,2,\\cdots\\) by induction or iterating the formula in the definition. We say \\(\\{X_n\\}\\) is a martingale (sub or super) if and only if \\(\\{X_n,\\sigma(X_1,\\cdots,X_n)\\}\\) is a martingale (sub or super). In fact, since \\(\\sigma(X_n)\\subset \\cal F_n\\), therefore \\(\\sigma(X_1,\\cdots,X_n)=\\sigma(\\sigma(X_1)\\cup\\cdots\\cup \\sigma(X_n))\\subset \\cal F_n\\) and thus \\(\\sigma(X_1,\\cdots,X_n)\\) is the smallest filtration \\(\\cal G_n\\) that satisfies \\(\\sigma(X_n) \\subset \\cal G_n\\) (or we say that \\(X_n\\) is ``adapted’’ to \\(\\cal G_n\\)). A construction of a martingale is to consider \\(E(Y|\\cal F_n)\\) for a integrable random variable \\(Y\\) and a filtration \\(\\{\\cal F_n\\}\\) by the rule of conditional expectation. The following example is known as likelihood ratio martingale. Example 2.13 Consider a sequence of random variables \\(\\{X_n\\}\\) from either \\(P\\) or \\(Q\\) that are measures on the space \\((\\Omega, \\cal F)\\). Let \\(P_n\\) and \\(Q_n\\) be \\(P\\) and \\(Q\\) restricted to \\(\\cal F_n=\\sigma(\\rm X_1,\\cdots,X_n)\\). Suppose that \\(Q_n \\ll P_n\\) for each \\(n\\). Then \\(\\{L_n,\\cal F_n\\}\\) is a martingale where \\(L_n=\\frac{dQ_n}{dP_n}\\). Moreover, suppose there exists a \\(\\sigma\\)-finite measure \\(\\nu_n\\) on \\(\\cal F_n\\) which is equivalent to \\(P_n\\). Then \\(L_n=\\frac{dQ_n}{d\\nu_n}/\\frac{dP_n}{d\\nu_n}\\) is called the likelihood ratio. The second example is known to be a simple random walk, which is a Markov chain as well as a martingale. Example 2.14 Let \\(\\{\\epsilon_n\\}\\) be a sequence of independent and integrable random variables. Let \\(X_n=\\sum_{i=1}^n \\epsilon_i\\). Then \\(\\{X_n\\}\\) is a martingale since \\[E(X_{n+1}|X_1,\\cdots,X_n)=E(X_n+\\epsilon_{n+1}|X_1,\\cdots,X_n)=X_n.\\] The following theorem can be intermediately derived by Jensen’s inequality on conditional expectation, i.e., for convex function \\(\\phi\\),\\[\\phi(X_n)=\\phi(E(X_{n+1}|\\cal F_n))\\leq \\rm E(\\phi(X_{n+1})|\\cal F_n).\\] Theorem 2.5 Let \\(\\phi\\) be a convex function on \\(\\mathbb{R}\\). If \\(\\{X_n,\\cal F_n\\}\\) is a martingale and \\(\\phi(X_n)\\) is integrable for all \\(n\\), then \\(\\{\\phi(X_n),\\cal F_n\\}\\) is a submartingale. If \\(\\{X_n,\\cal F_n\\}\\) is a submartingale and \\(\\phi(X_n)\\) is integrable for all \\(n\\), and \\(\\phi\\) is non-decreasing, then \\(\\{\\phi(X_n),\\cal F_n\\}\\) is a submartingale. A well-known result of martingale comes from Doob’s decomposition which decompose any adapted stochastic process \\(X_n\\) (i.e. \\(\\sigma(X_n)\\subset \\cal F_n\\) for all \\(n\\)) into a martingale \\(Y_n\\) and a predictable process \\(Z_n\\) (i.e. \\(Z_n\\) is measurable with respect to \\(\\cal F_n\\) for all \\(n\\)). The following theorem is an extension of Doob’s decomposition. Theorem 2.6 Let \\(\\{X_n, \\cal F_n\\}\\) be a submartingale (supermartingale). Then \\(X_n=Y_n+Z_n\\) for all \\(n\\) where \\(\\{Y_n, \\cal F_n\\}\\) is a martingale, and \\(Z_n\\) is an increasing (decreasing) sequence with \\(EZ_n&lt;\\infty\\) for all \\(n\\). Furthermore, if \\(\\mathrm{sup}_n E|X_n|&lt;\\infty\\), then \\(\\mathrm{sup}_n E|Y_n|&lt;\\infty\\) and \\(\\mathrm{sup}_n EZ_n&lt;\\infty\\). The decomposition can be constructed by letting \\(Y_n=\\sum_{i=1}^{n} \\eta_i\\) and \\(Z_n=\\sum_{i=1}^{n} \\xi_i\\) for \\(\\eta_i=X_i-X_{i-1}-E(X_i-X_{i-1}|\\cal F_{i-1})\\), \\(\\xi_i=E(X_i-X_{i-1}|\\cal F_{i-1})\\) and \\(\\eta_1=\\xi_1=0\\). The last theorem in this chapter is the convergence theorem of martingales given by Doob. Theorem 2.7 Let \\(\\{X_n, \\cal F_n\\}\\) be a submartingale. If \\(c:=\\sup_n E|X_n|&lt;\\infty\\), then \\(\\lim_{n\\to \\infty}X_n \\to X\\) a.s., where \\(X\\) is a random variable satisfying \\(E|X|\\leq c\\). "],["asymptotical-theory.html", "2.4 Asymptotical Theory", " 2.4 Asymptotical Theory 2.4.1 Convergence modes In this chapter we shall recall four types of convergence at first. We may keep the notation as in undergraduate mathematical statistics. Definition 2.12 Let \\(X,X_1,X_2,\\cdots\\) be random \\(k\\)-vectors defined on a probability space. \\(X_n\\stackrel{a.s.}\\to X\\) if and only if \\(X_n\\to X\\) \\(P\\)-a.e. \\(X_n\\stackrel{p}\\to X\\) if and only if for fixed \\(\\epsilon&gt;0\\), \\[P(|X_n-X|&gt;\\epsilon)\\to 0.\\] \\(X_n\\stackrel{L^r}\\to X\\) for \\(r\\geq 0\\) if and only if \\[E(||X_n-X||^r)\\to 0.\\] \\(X_n\\stackrel{d}\\to X\\) if and only if for each continuity point \\(x\\) of c.d.f of \\(X\\), \\(F\\) and \\(X_n \\sim F_n\\), we have \\[F_n(x)\\to F(x).\\] By Markov inequality, \\(X_n\\stackrel{L^r}\\to X\\) implies \\(X_n\\stackrel{p}\\to X\\). Clearly, \\(X_n\\stackrel{a.s.}\\to X\\) also implies \\(X_n\\stackrel{p}\\to X\\). Furthermore, we have \\(X_n\\stackrel{p}\\to X\\) implies \\(X_n\\stackrel{d}\\to X\\) and inverse holds if \\(X\\) is a constant. We also recall the so called infinitely often (i.o.) refers to the limit supremum of the sets. In other words, an event \\(A_n\\) happens i.o. if and only \\(\\cap_{k=1}^{\\infty} \\cup_{n=k}^{\\infty} A_k\\) happens. Consider \\(A_n=\\{||X_n-X||&gt;\\epsilon\\}\\) for a given \\(\\epsilon&gt;0\\). Lemma 2.2 \\(X_n\\stackrel{a.s.}\\to X\\) if and only if for every \\(\\epsilon&gt;0\\), \\[P(\\mbox{limsup}_n\\{||X_n-X||&gt;\\epsilon\\})=0.\\] Proof. Clearly, for \\(\\omega \\in \\mbox{limsup}_n\\{||X_n-X||&gt;\\epsilon\\}\\), \\(X_n(\\omega) \\nrightarrow X(\\omega)\\). Thus \\(X_n\\stackrel{a.s.}\\to X\\) implies \\(P(\\mbox{limsup}_n\\{||X_n-X||&gt;\\epsilon\\})=0.\\). On the contrary, consider the set \\[A_j:=\\cup_{n=1}^\\infty\\cap_{m=n}^\\infty\\{||X_m-X||\\leq j^{-1}\\}.\\] Then the result follows from \\[\\cap_{j=1}^\\infty A_j=\\{\\omega: \\lim_{n\\to\\infty}X_n(\\omega)=X(\\omega)\\}.\\] Theorem 2.8 (Borel Cantelli Lemma) Let \\(A_n\\) be a sequence of events in probability space and follow the notation of limsup. If \\(\\sum_n P(A_n)&lt;\\infty\\), then \\(P(\\mbox{limsup}_n A_n)=0\\) If \\(A_1,A_2,\\cdots\\) are pairwise independent and \\(\\sum_n P(A_n)=\\infty\\), then \\(P(\\mbox{limsup}_n A_n)=1\\). The first B-C lemma are usually used in proving convergence almost surely. Below we start to consider the convergence with continuous function composite the random sequence. Clearly, if \\(X_n\\stackrel{a.s.}\\to X\\) then we have \\(f(X_n)\\stackrel{a.s.}\\to f(X)\\) for any continuous function \\(f\\). To show, for example, the case of convergence in distribution, we introduce the following theorem. Theorem 2.9 (Skorohod's Theorem) If \\(X_n\\stackrel{d}\\to X\\) (in particular, \\(X_n\\) and \\(X\\) need not to be definied on the same space), then there are random vectors \\(Y,Y_1,Y_2,\\cdots\\) defined on a common probability space such that \\(P_Y=P_X\\), \\(P_Y=P_X\\) for all \\(n\\) and \\(Y_n\\stackrel{a.s.}\\to X\\). With Skorohod’s theorem, it is easy to show that if \\(X_n\\stackrel{d}\\to X\\), then \\(f(X_n)\\stackrel{d}\\to f(X)\\) as long as we consider the \\(Y,Y_n\\)-copy on another probability space. These kinds of results are called ``continuous mapping theorem’’ which hold for convergence a.s., in distribution, and in probability. Exercise 2.3 Prove the continuous mapping theorem for the version of convergence in probability. In the following, we define the notation of small-o and big-o in the sense of probability and almost surely. Definition 2.13 Let \\(X_1,X_2,\\cdots\\) and \\(Y_1,Y_2,\\cdots\\) be random variables defined on a common probability space. \\(X_n=O(Y_n)\\) a.s. iff \\(P(||X_n||=O(|Y_n|))=1\\) \\(X_n=o(Y_n)\\) a.s. iff \\(\\frac{X_n}{Y_n}\\to 0\\) a.s. \\(X_n=O_p(Y_n)\\) iff for any \\(\\epsilon &gt;0\\), there is a constant \\(C_{\\epsilon}&gt;0\\) such that \\(\\mbox{sup}_n P(||X_n||\\geq C_{\\epsilon}|Y_n|)&lt; \\epsilon\\). \\(X_n=o_p(Y_n)\\) iff \\(\\frac{X_n}{Y_n}\\to 0\\) in probability. Obviously we can show that \\(X_n=o_p(1)\\) implies that \\(X_n=O_p(1)\\). Some intuitive properties listed below is left for exercise. Exercise 2.4 Here we list some propositions of big-o and small-o, we may abuse the notation to be clear: If \\(X_n\\stackrel{d}\\to X\\), then \\(X_n=O_p(1)\\). \\(o_p(1)+o_p(1)=o_p(1)\\). \\(O_p(1)\\times o_p(1)=o_p(1)\\). It still holds if changing \\(o_p(1)\\) with \\(O_p(1)\\) in 2. and 3. Theorem 2.10 Let \\(X,X_1,X_2,\\cdots\\) be random vectors. Then the following conditions are equivalent to weak convergence (convergence in distribution): (Levy-Cramer continuity theorem) For all \\(t\\in \\mathbb{R}.\\) \\[\\lim_{n\\to \\infty}E[e^{itX_n}]=E[e^{itX}].\\] \\(E[h(X_n)]\\to E[h(X)]\\) for every bounded continuous function \\(h\\). (Cramer-Wold device) For every real vector \\(c\\), \\(c^TX_n \\stackrel{d}\\to c^TX\\). Theorem 2.11 (Slutsky) If \\(X_n \\stackrel{d}\\to X\\) and \\(Y_n\\stackrel{p}\\to c\\), then \\(X_n+Y_n\\stackrel{d}\\to X+c\\). \\(X_nY_n\\stackrel{d}\\to cX\\). For the first case of Slutsky’s theorem, note that \\[P(X_n+Y_n\\leq t)=P(X_n+c+Y_n-c\\leq t, |Y_n-c|\\leq \\epsilon)+P(X_n+c+Y_n-c\\leq t, |Y_n-c|\\leq \\epsilon).\\] Then if \\(X\\)’s cdf \\(F_X\\) is continuous at \\(t-c+\\epsilon\\) and \\(t-c-\\epsilon\\). Since \\[F_X(t-c-\\epsilon)\\leq P(X_n+Y_n\\leq t) \\leq F_X(t-c+\\epsilon),\\] the convergence follows by taking \\(\\epsilon \\to 0\\). (In particular, notice that \\(F_X\\) is discontinuous at most countable points). An intermediate result of slutsky’s theorem (along with continuous mapping theorem and Cramer-Wold device) is that if \\(X_n \\stackrel{d}\\to X\\) and \\(Y_n\\stackrel{p}\\to c\\), then we have \\((X_n,Y_n) \\stackrel{d}\\to (X,Y).\\) Theorem 2.12 (Delta method) Let \\(a_n&gt;0\\), \\(a_n\\to \\infty\\), and \\(a_n(X_n-\\mu)\\stackrel{d}\\to Z\\) for some constant \\(\\mu\\) and random variable \\(Z\\). If \\(g\\) is differentiable at \\(\\mu\\), then \\[a_n(g(X_n)-g(\\mu))\\stackrel{d}\\to g&#39;(\\mu)Z.\\] Proof. By skorohod theorem, there exists \\(Y\\sim Z\\) and \\(Y_n=\\frac{U_n}{a_n}+\\mu\\) which satisfies \\(Y_n\\sim X_n\\) and \\(U_n=a_n(Y_n-\\mu)\\). Then by Taylor expansion and let \\(\\epsilon(x)=\\frac{g(x)-g(\\mu)-g&#39;(\\mu)(x-\\mu)}{x-\\mu}\\) for \\(x\\neq0\\) and \\(0\\) otherwise. Note that \\(\\lim_{x\\to\\mu}\\epsilon(x)=0\\). Finally, \\[a_n(g(Y_n)-g(\\mu))=a_n(g&#39;(\\mu)(Y_n-\\mu)+\\epsilon(Y_n)(Y_n-\\mu)).\\] Then the result quickly follows. Remark. If we replace \\(\\mu\\) with a random variable \\(X\\), does the result of Delta method still hold? In other words, if \\(a_n(X_n-X)\\stackrel{d}\\to Z\\), is \\(a_n(g(X_n)-g(X))\\stackrel{d}\\to g&#39;(X)Z\\)? False, for example, take \\(X_n=X+n^{-1/2}(-1)^nZ\\) for \\(Z\\sim-Z\\). Then \\[\\sqrt{n}(X_n-X)\\stackrel{d}\\to Z\\] but \\[\\sqrt{n}(X_n^2-X^2)\\sim 2(-1)^nXZ,\\] which is not convergent if we consider \\(X=Z\\). 2.4.2 Law of Large Numbers The law of large numbers, including weak law (WLLN) and strong law (SLLN), concerns the limiting behavior of sums of independent (not necessary identical) random variables. We will show the result of i.i.d. version and leave independent (without identical assumption) version to readers. Theorem 2.13 (WLLN) Let \\(X_1,X_2,\\cdots\\) be i.i.d. random variables. Then \\[\\frac{1}{n}\\sum_{i=1}^n X_i-a_n\\stackrel{p}\\to 0\\] if and only if \\[nP(|X_1|&gt;n)\\to 0,\\] where \\(a_n=E(X_1I_{\\{|X_1|\\leq n\\}})\\). Proof. We only prove the sufficiency. Consider truncating \\(X_i\\)’s, \\(Y_{n,j}=X_jI_{\\{|X_j|\\leq n\\}}\\). Let \\(T_n=\\sum_{i=1}^nX_i\\) and \\(Z_n=\\sum_{i=1}^nY_{n,i}\\). Note that \\(a_n=\\frac{EZ_n}{n}\\)Then \\[P(|\\frac{T_n-EZ_n}{n}|)&gt;\\epsilon)\\leq P(|\\frac{Z_n-EZ_n}{n}|)&gt;\\epsilon)+P(T_n\\neq Z_n).\\] The second term will tend to \\(0\\) since \\[P(T_n\\neq Z_n)\\leq \\sum_{i=1}^n P(Y_{n,i}\\neq X_i)=nP(|X_1&gt;n|)\\to 0.\\] By Chebyshev inequality, i.i.d. assumption, Cauchy inequality, we have \\[P(|\\frac{Z_n-EZ_n}{n}|)&gt;\\epsilon)\\leq \\frac{\\mbox{E}(Y_{n,1}^2)}{\\epsilon^2n}.\\] Then by the equality \\(E(Y^p)=\\int py^{p-1}P(Y&gt;y)dy\\) for random variable\\(Y&gt;0\\) and change of variables, we can derive that \\[\\frac{\\mbox{E}(Y_{n,1}^2)}{n} \\leq \\frac{1}{n}\\int_{0}^\\infty 2yP(|Y_{n,1}|&gt;y)dy\\leq c\\int_{0}^n 2yP(|X_1|&gt;y)dy.\\] For the last term \\(\\int_{0}^n 2yP(|X_1|&gt;y)dy\\), since \\(g(y):=2yP(|X_1|&gt;y)\\to 0\\), there exists \\(M=\\sup g(y)&lt;\\infty\\) and \\(\\epsilon_K=\\sup\\{g(y):y&gt;K\\}\\). Then \\[\\frac{1}{n}\\int_{0}^n 2yP(|X_1|&gt;y)dy\\leq \\frac{KM}{n}+\\frac{(n-K)\\epsilon_K}{n}.\\] Let \\(n\\to \\infty\\), then \\[\\limsup_{n\\to \\infty}\\frac{1}{n}\\int_{0}^n 2yP(|X_1|&gt;y)dy\\leq \\epsilon_K.\\] The result follows since \\(K\\) is arbitrary chosen and \\(\\epsilon_K\\to 0\\) as \\(K\\to \\infty\\). Theorem 2.14 (SLLN) Let \\(X_1,X_2,\\cdots\\) be i.i.d. random variables. Then \\[\\frac{1}{n}\\sum_{i=1}^n X_i \\stackrel{a.s.}\\to EX_1\\] if and only if \\(E|X_1|&lt;\\infty\\). Before proving the theorem, we may first discuss some related lemma which will be used in the proof. The first lemma is called Kronecker’s lemma. Lemma 2.3 (Kronecker's lemma) Let \\(x_n\\in \\mathbb{R}\\), \\(a_n\\in \\mathbb{R}\\), \\(0&lt;a_n\\leq a_{n+1}\\) for \\(n \\in \\mathbb{N}\\) and \\(a_n \\to \\infty\\). If \\(\\sum_{n=1}^\\infty x_n/a_n\\) converges, then \\(\\frac{1}{a_n}\\sum_{i=1}^n x_i \\to 0\\). The second lemma is a quite general inequality, due to Hajek and Renyi, we will give the proof of its special case which is known as Kolmogorov inequality and connect this result with Doob’s martingale inequality as a supplement for the last chapter. Lemma 2.4 (Hajek-Renyi) Let \\(Y_1,\\cdots, Y_n\\) be independent random variables with finite variances. Then \\[P(\\max_{1\\leq k\\leq n}c_k|\\sum_{i=1}^k (Y_i-(EY_i))|&gt;t )\\leq \\frac{1}{t^2}\\sum_{i=1}^n c_i^2\\mbox{Var}(Y_i),\\] for any \\(t&gt;0\\) and \\(c_1\\geq c_2 \\geq \\cdots\\geq c_n &gt;0\\). If \\(c_i=1\\) for all \\(i\\), the inequality reduces to “Kolmogorov inequality”. Proof (special case (Kolmogorov inequality)). Let \\(\\sum_{i=1}^nY_i-E(Y_i)=S_n\\) for \\(n\\in \\mathbb{N}\\). Then by Example 2.14, we have known that \\(S_1,S_2,\\cdots, S_n\\) forms a martingale. Let \\(Z_0=0\\) and \\(Z_{i+1}\\) be \\(S_{i+1}\\) if \\(\\max_{j\\leq i}|S_j|&lt; t\\), \\(Z_i\\) otherwise. Then \\(\\{Z_i\\}\\) is a martingale. To see this, note that \\(Z_{i}=S_i\\) for all \\(i\\) if \\(\\max_{j\\in\\mathbb{N}}|S_j|&lt; t\\), otherwise we can find a positive integer \\(K\\) such that \\(\\max_{j\\leq K}|S_j|&lt; t\\) and \\(\\max_{j\\leq K+1}|S_j|=|S_{K+1}|\\geq t\\) which implies \\(Z_i=S_i\\) for all \\(i\\leq K+1\\) and \\(Z_{i+1}=Z_{i}=S_{K+1}\\) for all \\(i\\geq K+1\\). In both cases \\(\\{Z_i\\}\\) is a martingale. Furthermore, \\[\\begin{split} P(\\max_{1\\leq i\\leq n} |S_i|\\geq t) &amp;=P(|Z_n|\\geq n)\\\\ &amp;\\leq \\frac{1}{\\lambda^2}E(Z_n^2)\\\\ &amp;=\\frac{1}{\\lambda^2}\\sum_{i=1}^n E[(Z_i-Z_{i-1})^2]\\\\ &amp;\\leq \\frac{1}{\\lambda^2}\\sum_{i=1}^n E[(S_i-S_{i-1})^2]=\\frac{1}{\\lambda^2}E(S_n^2)=\\frac{1}{\\lambda^2}\\mbox{Var}(S_n) \\end{split}\\] The first equality can be seen from the argument above. The second inequality is Chebyshev inequality. The left ones are based on the result that for any martingale \\(\\{M_n\\}\\) with \\(M_0=0\\), we have \\[\\sum_{i=1}^n E[(M_i-M_{i-1})^2]=E(M_n^2),\\] which holds since in particular \\[E(M_{i-1}(M_i-M_{i-1}))=0\\] for all \\(i\\geq 1\\). Another extension of Kolmogorov inequality is related to the proof based on the martingales. Further discussions and its proof can be referred to Section 35 in Bilingsley (2008). Proposition 2.8 (Doob's martingale inequality) If \\(X_1,\\cdots,X_n\\) is a submartingale, then for \\(\\alpha&gt;0\\), \\[P(\\max_{1\\leq i\\leq n}X_i\\geq \\alpha)\\leq \\frac{1}{\\alpha}E(|X_n|).\\] Let \\(X_i=S_i^2\\) be the partial sum of independent random variables with mean \\(0\\) and finite variances, which forms a submartingale by Theorem 2.5, then the result is exactly the Kolmogorov inequality. Proof (SLLN). We only show the sufficiency here. Let \\(Y_n=X_nI_{\\{|X_n|\\leq n\\}}\\), \\(n=1,2,\\cdots\\). To show the result, we consider the following decomposition: \\[\\begin{split} \\frac{1}{n}\\sum_{i=1}^n X_i-EX_1&amp;=(\\frac{1}{n}\\sum_{i=1}^n X_i-\\frac{1}{n}\\sum_{i=1}^n Y_i)\\\\ &amp;+\\frac{1}{n}\\sum_{i=1}^n (Y_i-EY_i)+\\frac{1}{n}\\sum_{i=1}^n (EY_i-EX_1). \\end{split}\\] Since \\(EY_n\\to EX_1\\) by LDCT, It can be seen that the third term \\(\\frac{1}{n}\\sum_{i=1}^n (EY_i-EX_1) \\to 0\\) (just separate the sum by finite terms and tail sum). For the first term, by integral test and \\(E|X_1|=\\int P(|X_1|&gt;x)dx &lt;\\infty\\) we have \\[\\sum_{n=1}^\\infty P(X_n\\neq Y_n)=\\sum_{n=1}^\\infty P(|X_n|&gt;n)=\\sum_{n=1}^\\infty P(|X_n|&gt;n)&lt;\\infty.\\] Then by Borel-Cantelli first lemma, we have \\(P(\\{X_m\\neq Y_m\\, ,i.o.\\})=0\\). Hence for sufficiently large \\(n\\) we have \\(X_n=Y_n\\) with probability \\(1\\). Thus \\[\\frac{1}{n}\\sum_{i=1}^n X_i-\\frac{1}{n}\\sum_{i=1}^n Y_i \\to 0 \\quad a.s.\\] (similarly by separating the sum into finite sum and tail sum.) Thereore, it remains to show the second term \\(\\frac{1}{n}\\sum_{i=1}^n (Y_i-EY_i) \\to 0\\) a.s.. To show this, we define \\(Z_1=\\cdots=Z_{m-1}=0\\), \\(Z_m=Y_1+\\cdots+Y_m\\), and \\(Z_i=Y_i\\) for \\(i\\geq m+1\\) and \\(c_i=\\frac{1}{i}\\) for \\(i\\geq m\\) in Hajek-Renyi inequality. Then we can derive that \\[P(\\max_{m\\leq l\\leq n}|\\xi_l|&gt;\\epsilon)\\leq \\frac{1}{\\epsilon^2m^2} \\sum_{i=1}^m \\mbox{Var}(Y_i)+\\frac{1}{\\epsilon^2}\\sum_{i=m+1}^n \\frac{\\mbox{Var}(Y_i)}{i^2},\\] where \\(\\xi_n=n^{-1}\\sum_{i=1}^n (Z_i-EZ_i)=n^{-1}\\sum_{i=1}^n (Y_i-EY_i)\\) for \\(n\\geq m\\). Note that \\[\\begin{split} \\sum_{n=1}^\\infty \\frac{EY_n^2}{n^2}&amp;=\\sum_{n=1}^\\infty \\sum_{j=1}^n \\frac{E(X_1^2 I_{\\{j-1&lt;|X_1|\\leq j\\}})}{n^2}\\\\ &amp;\\leq \\sum_{j=1}^\\infty \\sum_{n=j}^\\infty j\\frac{E(|X_1| I_{\\{j-1&lt;|X_1|\\leq j\\}})}{n^2}&lt;\\infty, \\end{split}\\] where the last inequality holds since \\(\\sum_n \\frac{j}{n^2}&lt;\\infty\\). It suffices to show that \\(\\xi_n=n^{-1}\\sum_{i=1}^n (Y_i-EY_i) \\to 0\\) a.s.. To see this, by lemma 2.2, we only need to show that \\(P(\\limsup_n \\{|\\xi_n|&gt;\\epsilon\\})=0\\). This follows from \\[\\begin{split} P(\\limsup_n \\{|\\xi_n|&gt;\\epsilon\\})&amp;=\\lim_{n\\to \\infty} P(\\cup_{l=n}^\\infty \\{|\\xi_l|&gt;\\epsilon\\} )\\\\ &amp;=\\lim_{n\\to \\infty}\\lim_{k\\to\\infty} P(\\max_{n\\leq l \\leq k}|\\xi_l|&gt;\\epsilon)\\\\ &amp;\\leq \\lim_{n\\to \\infty} \\frac{1}{\\epsilon^2 n^2}\\sum_{i=1}^n \\mbox{Var}(Y_i)+\\frac{1}{\\epsilon^2} \\sum_{i=n+1}^\\infty \\frac{\\mbox{Var}(Y_i)}{i^2}=0. \\end{split}\\] The last equality follows by Kronecker’s lemma and \\(\\sum_{n=1}^\\infty \\frac{EY_n^2}{n^2}&lt;\\infty\\). 2.4.3 Central Limit Theorem Consider \\(\\{X_{n,j},j=1,\\cdots,k_n\\}\\) be independent random variables with \\(0&lt;\\sigma_n^2=\\mbox{Var}(\\sum_{j=1}^{k_n}X_{n,j})&lt;\\infty\\) \\(n=1,2,\\cdots\\) for \\(k_n\\to \\infty\\) as \\(n\\to \\infty\\). Here we discuss some different conditions such that the following result holds. \\[\\frac{1}{\\sigma_n} \\sum_{j=1}^{k_n} (X_{n,j}-E(X_{n,j})) \\stackrel{d}\\to N(0.1).\\] The first condition is called Linderberg condition, which assumes that \\[\\sum_{j=1}^{k_n} E[(X_{n,j}-E(X_{n,j}))^2I_{\\{|X_{n,j}-E(X_{n,j})|&gt;\\epsilon\\sigma_n\\}}]=o(\\sigma_n^2) \\] for any \\(\\epsilon&gt;0\\). The second one is Lyapunov’s condition: \\[\\sum_{j=1}^{k_n} E|X_{n,j}-EX_{n,j}|^{2+\\delta}=o(\\sigma_n^{2+\\delta}),\\] which is more common and will imply Linderberg’s condition. The last one is implied by Linderberg’s conditon, which is called Feller’s condition: \\[\\lim_{n\\to \\infty} \\frac{\\max_{j\\leq k_n}\\sigma_{n,j}^2}{\\sigma_n^2}=0, \\] where \\(\\sigma_{n,j}^2=\\mbox{Var}(X_n,j)\\). In summary, we have the following: \\[\\mbox{Lyapunov&#39;s condition}\\Rightarrow \\mbox{Linderberg&#39;s condition}\\Rightarrow \\mbox{Feller&#39;s condition}.\\] Exercise 2.5 Show the result about the implication of the conditions for CLT above. (\\(\\mbox{Lyapunov&#39;s condition}\\Rightarrow \\mbox{Linderberg&#39;s condition}\\)) (\\(\\mbox{Linderberg&#39;s condition}\\Rightarrow \\mbox{Feller&#39;s condition}\\)) It is clear since \\[\\frac{\\max_{j\\leq k_n} \\mbox{Var}(Y_{n,j})}{\\sigma_n^2}\\leq \\frac{1}{\\sigma_n^2}(\\sum_{j=1}^{k_n}E(Y_{n,j}^2))I_{\\{|X_{n,j}-E(X_{n,j})|&gt;\\epsilon\\sigma_n\\}}+\\epsilon^2\\sigma_n^2),\\] thus the result follows by the Linderberg’s condition. Example 2.15 (density estimation) \\(X_1,X_2,\\cdots\\) be IID with Lebesgue PDF \\(f\\). Consider \\[\\hat{f}(x_0)=\\frac{1}{nh}\\sum_{i=1}^n k(\\frac{x_0-x_i}{h}),\\] where \\(0&lt;h=h_n\\to 0\\) and \\(k\\) is kernel function which satisfies (i) \\(k\\geq 0\\), (ii)\\(\\int k(u) du=1\\), (iii)\\(\\int u k(u) du=0\\) (iv) \\(\\int u^2 k(u) du&lt;\\infty\\). Determine the conditions such that we have \\[\\frac{nh_n(\\hat{f}(x_0)-f(x_0))}{\\sqrt{\\mbox{Var}(nh_n\\hat{f}(x_0))}} \\stackrel{d} \\to N(0,1). \\] By Lyapunov’s condition, we may require that \\[\\frac{\\sum_i E|k(\\frac{x_0-X_i}{h})-E(k(\\frac{x_0-X_i}{h}))|^{2+\\delta}}{\\sqrt{\\mbox{Var}(\\sum_i k(\\frac{x_0-X_i}{h}))}^{2+\\delta}} \\to 0. \\] Let \\(g=k,k^2\\), \\[E(g(\\frac{x_0-X_i}{h}))=\\int_{-\\infty}^{\\infty} g(\\frac{x_0-x}{h})f(x)dx=\\int_{-\\infty}^{\\infty} g(u)f(x_0-hu)hdu.\\] By LDCT, \\[E(k^2(\\frac{x_0-X_i}{h}))=h_n(f(x_0)\\int_{-\\infty}^{\\infty}k^2(u)du+o(1)),\\] and \\[E(k(\\frac{x_0-X_i}{h}))=h_n(f(x_0)+o(1)).\\] Then by considering \\(\\delta=2\\) for Lyapunov’s condition and \\[ \\sum_i E|k(\\frac{x_0-X_i}{h})-E(k(\\frac{x_0-X_i}{h}))|^{4}\\leq Cnh_n(1+o(1)),\\] for some constant \\(C\\). Then the Lyapunov’s condition can therefore be verified by \\(nh_n\\to \\infty\\). We may wonder that at what circumstances we will encounter the general type of CLT, which admits two indices (\\(n,j\\)). Below we illustrate an example. Example 2.16 Consider the model \\(Y=f(X)+\\epsilon\\) and \\(X\\in[0,1]\\). If we sample “\\(X\\)” as to be \\(\\{X_{n,1},\\cdots,X_{n,k_n}\\}=\\{\\frac{1}{k_n+1},\\cdots,\\frac{k_n}{k_n+1}\\}\\) and \\(Y_{n,j}=f(X_{n,j})+\\epsilon_{n,j}\\), where \\(\\epsilon_{n,j}\\stackrel{IID}\\sim N(0,\\sigma^2)\\). If we consider \\[\\hat{f}(x_0)=\\frac{\\sum_{j=1}^{k_n}Y_{n,j}k(\\frac{x_0-X_{n,j}}{h})}{k(\\frac{x_0-X_{n,j}}{h})}.\\] Then the form \\[\\hat{f}(x_0)-\\frac{\\sum_{j=1}^{k_n}f(X_{n,j})k(\\frac{x_0-X_{n,j}}{h})}{k(\\frac{x_0-X_{n,j}}{h})}=\\frac{\\sum_{j=1}^{k_n}\\epsilon_{n,j}k(\\frac{x_0-X_{n,j}}{h})}{k(\\frac{x_0-X_{n,j}}{h})}\\] involves the sum of random variables with two indices. In proving Linderberg’s CLT, we consider the characteristic function of \\(\\frac{1}{\\sigma_n} \\sum_{j=1}^{k_n} (X_{n,j}-E(X_{n,j}))\\), the inequality \\[|\\prod_{k=1}^m Ea_k-\\prod_{k=1}^m Eb_k|\\leq\\sum_{j=1}^m E|a_k-b_k|,\\] and \\[Ee^{itX_{n,j}}-(1-t^2\\sigma_{n,j}^2/2)\\leq E(\\min\\{|tX_{n,j}|^2,|tX_{n,j}|^3\\}).\\] Combining the two inequalities and the approximation of c.h.f, we may separate and control the two parts \\(I_{\\{|X_{n,j}-E(X_{n,j})|&gt;\\epsilon\\}}\\) and \\(I_{\\{|X_{n,j}-E(X_{n,j})| \\leq\\epsilon\\}}\\). The result (for the squared term) will naturally follow by the Linderberg’s condition. "]]
